{
  "problem_id": "user_unregistered_mongodb-localization-1",
  "system_state_summary": "在test-hotel-reservation命名空间中部署的酒店预订系统出现服务故障。核心问题是geo服务的Pod处于CrashLoopBackOff状态，持续重启失败。具体表现为：\n\n**故障核心**：\n- Pod名称：geo-84fbc958c7-zcfdf\n- 状态：CrashLoopBackOff，已重启3次\n- 退出码：2（表示配置或连接错误）\n- 容器镜像：yinfangchen/hotelreservation:latest\n- 端口配置：8083/TCP\n\n**关键报错信息**：\n容器启动后立即终止，Exit Code为2，从启动到结束仅持续数秒（Started: 16:29:26, Finished: 16:29:26）。Back-off重启策略已触发，当前处于退避等待状态。\n\n**受影响资源**：\n- Deployment: geo（副本数1/1，但实际可用0）\n- ReplicaSet: geo-84fbc958c7\n- 节点：kind-worker (172.18.0.4)\n- IP地址：10.244.1.69\n\n**集群状态**：\n- 其他服务（consul, frontend, jaeger, memcached-profile等）运行正常\n- 节点kind-worker状态正常\n- 网络插件和存储正常\n\n**环境配置**：\n- JAEGER_SAMPLE_RATIO设置为1\n- 资源限制：CPU限制1核，请求100m\n- 存在Istio sidecar注解配置\n\n**可能原因**：\n基于Exit Code 2和快速崩溃的特征，极可能是geo服务依赖的MongoDB数据库连接失败、配置文件缺失或环境变量配置错误导致服务无法启动。",
  "execution_info": {
    "start_time": "2025-12-24T18:17:52.765742",
    "end_time": "2025-12-24T18:18:51.278427",
    "duration_seconds": 58.512685,
    "total_commands": 66,
    "successful_commands": 65,
    "failed_commands": 1
  },
  "commands": [
    {
      "original_command": "exec_shell(\"kubectl get all -n test-hotel-reservation -o wide\")",
      "command": "exec_shell(\"kubectl get all -n test-hotel-reservation-f819b557 -o wide\")",
      "result": "NAME                                          READY   STATUS    RESTARTS      AGE   IP             NODE          NOMINATED NODE   READINESS GATES\npod/consul-78c8d79bb-qtch4                    1/1     Running   0             33s   10.244.1.183   kind-worker   <none>           <none>\npod/frontend-7fc7ddc9db-tp7km                 1/1     Running   0             33s   10.244.1.184   kind-worker   <none>           <none>\npod/geo-84fbc958c7-v9jpp                      0/1     Error     1 (11s ago)   12s   10.244.1.208   kind-worker   <none>           <none>\npod/jaeger-67445b6dd6-mz9dd                   1/1     Running   0             33s   10.244.1.187   kind-worker   <none>           <none>\npod/memcached-profile-668dcd6dbb-xk8vx        1/1     Running   0             33s   10.244.1.188   kind-worker   <none>           <none>\npod/memcached-rate-5b666ddfcb-s4s9p           1/1     Running   0             33s   10.244.1.191   kind-worker   <none>           <none>\npod/memcached-reserve-5bf87f5d54-gbdxj        1/1     Running   0             32s   10.244.1.195   kind-worker   <none>           <none>\npod/mongodb-geo-5ff578bcb8-k5hd4              1/1     Running   0             11s   10.244.1.209   kind-worker   <none>           <none>\npod/mongodb-profile-758cb77f9f-fb9r6          1/1     Running   0             33s   10.244.1.200   kind-worker   <none>           <none>\npod/mongodb-rate-56cc8659c9-t765c             1/1     Running   0             33s   10.244.1.202   kind-worker   <none>           <none>\npod/mongodb-recommendation-55699465f7-f7d95   1/1     Running   0             32s   10.244.1.205   kind-worker   <none>           <none>\npod/mongodb-reservation-5994859869-4m59j      1/1     Running   0             32s   10.244.1.206   kind-worker   <none>           <none>\npod/mongodb-user-969c6c449-2cdt2              1/1     Running   0             31s   10.244.1.207   kind-worker   <none>           <none>\npod/profile-8b6dd7c6c-57q4n                   1/1     Running   1 (18s ago)   33s   10.244.1.190   kind-worker   <none>           <none>\npod/rate-7bdc978679-zkffp                     1/1     Running   1 (16s ago)   32s   10.244.1.193   kind-worker   <none>           <none>\npod/recommendation-6879fb56bf-hnbz5           1/1     Running   1 (13s ago)   32s   10.244.1.194   kind-worker   <none>           <none>\npod/reservation-78c9f7976b-5rfxh              1/1     Running   0             31s   10.244.1.197   kind-worker   <none>           <none>\npod/search-5c64c8f5bc-8gzg7                   1/1     Running   0             31s   10.244.1.198   kind-worker   <none>           <none>\npod/user-66d5d6f874-vtqcb                     1/1     Running   1 (15s ago)   31s   10.244.1.199   kind-worker   <none>           <none>\npod/wrk2-job-f819b557-k4w7n                   1/1     Running   0             4s    10.244.1.210   kind-worker   <none>           <none>\n\nNAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                       AGE   SELECTOR\nservice/consul                   ClusterIP   10.96.121.138   <none>        8300/TCP,8400/TCP,8500/TCP,8600/UDP                                           33s   io.kompose.service=consul\nservice/frontend                 ClusterIP   10.96.155.90    <none>        5000/TCP                                                                      33s   io.kompose.service=frontend\nservice/geo                      ClusterIP   10.96.129.251   <none>        8083/TCP                                                                      33s   io.kompose.service=geo\nservice/jaeger                   ClusterIP   10.96.138.87    <none>        14269/TCP,5778/TCP,14268/TCP,14267/TCP,16686/TCP,5775/UDP,6831/UDP,6832/UDP   33s   io.kompose.service=jaeger\nservice/jaeger-out               NodePort    10.96.84.128    <none>        16686:31512/TCP                                                               33s   io.kompose.service=jaeger\nservice/memcached-profile        ClusterIP   10.96.91.63     <none>        11211/TCP                                                                     33s   io.kompose.service=memcached-profile\nservice/memcached-rate           ClusterIP   10.96.147.165   <none>        11211/TCP                                                                     33s   io.kompose.service=memcached-rate\nservice/memcached-reserve        ClusterIP   10.96.175.194   <none>        11211/TCP                                                                     33s   io.kompose.service=memcached-reserve\nservice/mongodb-geo              ClusterIP   10.96.86.217    <none>        27017/TCP                                                                     33s   io.kompose.service=mongodb-geo\nservice/mongodb-profile          ClusterIP   10.96.2.190     <none>        27017/TCP                                                                     33s   io.kompose.service=mongodb-profile\nservice/mongodb-rate             ClusterIP   10.96.211.242   <none>        27017/TCP                                                                     33s   io.kompose.service=mongodb-rate\nservice/mongodb-recommendation   ClusterIP   10.96.103.58    <none>        27017/TCP                                                                     33s   io.kompose.service=mongodb-recommendation\nservice/mongodb-reservation      ClusterIP   10.96.244.129   <none>        27017/TCP                                                                     33s   io.kompose.service=mongodb-reservation\nservice/mongodb-user             ClusterIP   10.96.246.125   <none>        27017/TCP                                                                     33s   io.kompose.service=mongodb-user\nservice/profile                  ClusterIP   10.96.214.20    <none>        8081/TCP                                                                      33s   io.kompose.service=profile\nservice/rate                     ClusterIP   10.96.69.233    <none>        8084/TCP                                                                      33s   io.kompose.service=rate\nservice/recommendation           ClusterIP   10.96.56.244    <none>        8085/TCP                                                                      33s   io.kompose.service=recommendation\nservice/reservation              ClusterIP   10.96.244.90    <none>        8087/TCP                                                                      33s   io.kompose.service=reservation\nservice/search                   ClusterIP   10.96.213.167   <none>        8082/TCP                                                                      33s   io.kompose.service=search\nservice/user                     ClusterIP   10.96.105.29    <none>        8086/TCP                                                                      33s   io.kompose.service=user\n\nNAME                                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS                          IMAGES                                SELECTOR\ndeployment.apps/consul                   1/1     1            1           33s   consul                              hashicorp/consul:latest               io.kompose.service=consul\ndeployment.apps/frontend                 1/1     1            1           33s   hotel-reserv-frontend               yinfangchen/hotelreservation:latest   io.kompose.service=frontend\ndeployment.apps/geo                      0/1     1            0           33s   hotel-reserv-geo                    yinfangchen/hotelreservation:latest   io.kompose.service=geo\ndeployment.apps/jaeger                   1/1     1            1           33s   hotel-reserv-jaeger                 jaegertracing/all-in-one:1.57         io.kompose.service=jaeger\ndeployment.apps/memcached-profile        1/1     1            1           33s   hotel-reserv-profile-mmc            memcached:1.6.7                       io.kompose.service=memcached-profile\ndeployment.apps/memcached-rate           1/1     1            1           33s   hotel-reserv-rate-mmc               memcached:1.6.7                       io.kompose.service=memcached-rate\ndeployment.apps/memcached-reserve        1/1     1            1           33s   hotel-reserv-reservation-mmc        memcached:1.6.7                       io.kompose.service=memcached-reserve\ndeployment.apps/mongodb-geo              1/1     1            1           33s   hotel-reserv-geo-mongo              mongo:4.4.6                           io.kompose.service=mongodb-geo\ndeployment.apps/mongodb-profile          1/1     1            1           33s   hotel-reserv-profile-mongo          mongo:4.4.6                           io.kompose.service=mongodb-profile\ndeployment.apps/mongodb-rate             1/1     1            1           33s   hotel-reserv-rate-mongo             mongo:4.4.6                           io.kompose.service=mongodb-rate\ndeployment.apps/mongodb-recommendation   1/1     1            1           33s   hotel-reserv-recommendation-mongo   mongo:4.4.6                           io.kompose.service=mongodb-recommendation\ndeployment.apps/mongodb-reservation      1/1     1            1           33s   hotel-reserv-reservation-mongo      mongo:4.4.6                           io.kompose.service=mongodb-reservation\ndeployment.apps/mongodb-user             1/1     1            1           33s   hotel-reserv-user-mongo             mongo:4.4.6                           io.kompose.service=mongodb-user\ndeployment.apps/profile                  1/1     1            1           33s   hotel-reserv-profile                yinfangchen/hotelreservation:latest   io.kompose.service=profile\ndeployment.apps/rate                     1/1     1            1           33s   hotel-reserv-rate                   yinfangchen/hotelreservation:latest   io.kompose.service=rate\ndeployment.apps/recommendation           1/1     1            1           33s   hotel-reserv-recommendation         yinfangchen/hotelreservation:latest   io.kompose.service=recommendation\ndeployment.apps/reservation              1/1     1            1           33s   hotel-reserv-reservation            yinfangchen/hotelreservation:latest   io.kompose.service=reservation\ndeployment.apps/search                   1/1     1            1           33s   hotel-reserv-search                 yinfangchen/hotelreservation:latest   io.kompose.service=search\ndeployment.apps/user                     1/1     1            1           33s   hotel-reserv-user                   yinfangchen/hotelreservation:latest   io.kompose.service=user\n\nNAME                                                DESIRED   CURRENT   READY   AGE   CONTAINERS                          IMAGES                                SELECTOR\nreplicaset.apps/consul-78c8d79bb                    1         1         1       33s   consul                              hashicorp/consul:latest               io.kompose.service=consul,pod-template-hash=78c8d79bb\nreplicaset.apps/frontend-7fc7ddc9db                 1         1         1       33s   hotel-reserv-frontend               yinfangchen/hotelreservation:latest   io.kompose.service=frontend,pod-template-hash=7fc7ddc9db\nreplicaset.apps/geo-84fbc958c7                      1         1         0       33s   hotel-reserv-geo                    yinfangchen/hotelreservation:latest   io.kompose.service=geo,pod-template-hash=84fbc958c7\nreplicaset.apps/jaeger-67445b6dd6                   1         1         1       33s   hotel-reserv-jaeger                 jaegertracing/all-in-one:1.57         io.kompose.service=jaeger,pod-template-hash=67445b6dd6\nreplicaset.apps/memcached-profile-668dcd6dbb        1         1         1       33s   hotel-reserv-profile-mmc            memcached:1.6.7                       io.kompose.service=memcached-profile,pod-template-hash=668dcd6dbb\nreplicaset.apps/memcached-rate-5b666ddfcb           1         1         1       33s   hotel-reserv-rate-mmc               memcached:1.6.7                       io.kompose.service=memcached-rate,pod-template-hash=5b666ddfcb\nreplicaset.apps/memcached-reserve-5bf87f5d54        1         1         1       32s   hotel-reserv-reservation-mmc        memcached:1.6.7                       io.kompose.service=memcached-reserve,pod-template-hash=5bf87f5d54\nreplicaset.apps/mongodb-geo-5ff578bcb8              1         1         1       33s   hotel-reserv-geo-mongo              mongo:4.4.6                           io.kompose.service=mongodb-geo,pod-template-hash=5ff578bcb8\nreplicaset.apps/mongodb-profile-758cb77f9f          1         1         1       33s   hotel-reserv-profile-mongo          mongo:4.4.6                           io.kompose.service=mongodb-profile,pod-template-hash=758cb77f9f\nreplicaset.apps/mongodb-rate-56cc8659c9             1         1         1       33s   hotel-reserv-rate-mongo             mongo:4.4.6                           io.kompose.service=mongodb-rate,pod-template-hash=56cc8659c9\nreplicaset.apps/mongodb-recommendation-55699465f7   1         1         1       32s   hotel-reserv-recommendation-mongo   mongo:4.4.6                           io.kompose.service=mongodb-recommendation,pod-template-hash=55699465f7\nreplicaset.apps/mongodb-reservation-5994859869      1         1         1       32s   hotel-reserv-reservation-mongo      mongo:4.4.6                           io.kompose.service=mongodb-reservation,pod-template-hash=5994859869\nreplicaset.apps/mongodb-user-969c6c449              1         1         1       31s   hotel-reserv-user-mongo             mongo:4.4.6                           io.kompose.service=mongodb-user,pod-template-hash=969c6c449\nreplicaset.apps/profile-8b6dd7c6c                   1         1         1       33s   hotel-reserv-profile                yinfangchen/hotelreservation:latest   io.kompose.service=profile,pod-template-hash=8b6dd7c6c\nreplicaset.apps/rate-7bdc978679                     1         1         1       32s   hotel-reserv-rate                   yinfangchen/hotelreservation:latest   io.kompose.service=rate,pod-template-hash=7bdc978679\nreplicaset.apps/recommendation-6879fb56bf           1         1         1       32s   hotel-reserv-recommendation         yinfangchen/hotelreservation:latest   io.kompose.service=recommendation,pod-template-hash=6879fb56bf\nreplicaset.apps/reservation-78c9f7976b              1         1         1       32s   hotel-reserv-reservation            yinfangchen/hotelreservation:latest   io.kompose.service=reservation,pod-template-hash=78c9f7976b\nreplicaset.apps/search-5c64c8f5bc                   1         1         1       31s   hotel-reserv-search                 yinfangchen/hotelreservation:latest   io.kompose.service=search,pod-template-hash=5c64c8f5bc\nreplicaset.apps/user-66d5d6f874                     1         1         1       31s   hotel-reserv-user                   yinfangchen/hotelreservation:latest   io.kompose.service=user,pod-template-hash=66d5d6f874\n\nNAME                          STATUS    COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES                              SELECTOR\njob.batch/wrk2-job-f819b557   Running   0/1           4s         4s    wrk2         deathstarbench/wrk2-client:latest   batch.kubernetes.io/controller-uid=24741bef-e6aa-4fd8-86f1-e669f309eba9\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get nodes -o wide\")",
      "command": "exec_shell(\"kubectl get nodes -o wide\")",
      "result": "NAME                 STATUS   ROLES           AGE    VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION                     CONTAINER-RUNTIME\nkind-control-plane   Ready    control-plane   117m   v1.32.0   172.18.0.3    <none>        Debian GNU/Linux 12 (bookworm)   6.6.87.2-microsoft-standard-WSL2   containerd://1.7.24\nkind-worker          Ready    <none>          117m   v1.32.0   172.18.0.2    <none>        Debian GNU/Linux 12 (bookworm)   6.6.87.2-microsoft-standard-WSL2   containerd://1.7.24\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation --show-labels\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 --show-labels\")",
      "result": "NAME                                      READY   STATUS    RESTARTS      AGE   LABELS\nconsul-78c8d79bb-qtch4                    1/1     Running   0             35s   io.kompose.service=consul,pod-template-hash=78c8d79bb\nfrontend-7fc7ddc9db-tp7km                 1/1     Running   0             35s   io.kompose.service=frontend,pod-template-hash=7fc7ddc9db\ngeo-84fbc958c7-v9jpp                      0/1     Error     1 (13s ago)   14s   io.kompose.service=geo,pod-template-hash=84fbc958c7\njaeger-67445b6dd6-mz9dd                   1/1     Running   0             35s   io.kompose.service=jaeger,pod-template-hash=67445b6dd6\nmemcached-profile-668dcd6dbb-xk8vx        1/1     Running   0             35s   io.kompose.service=memcached-profile,pod-template-hash=668dcd6dbb\nmemcached-rate-5b666ddfcb-s4s9p           1/1     Running   0             35s   io.kompose.service=memcached-rate,pod-template-hash=5b666ddfcb\nmemcached-reserve-5bf87f5d54-gbdxj        1/1     Running   0             34s   io.kompose.service=memcached-reserve,pod-template-hash=5bf87f5d54\nmongodb-geo-5ff578bcb8-k5hd4              1/1     Running   0             13s   io.kompose.service=mongodb-geo,pod-template-hash=5ff578bcb8\nmongodb-profile-758cb77f9f-fb9r6          1/1     Running   0             35s   io.kompose.service=mongodb-profile,pod-template-hash=758cb77f9f\nmongodb-rate-56cc8659c9-t765c             1/1     Running   0             35s   io.kompose.service=mongodb-rate,pod-template-hash=56cc8659c9\nmongodb-recommendation-55699465f7-f7d95   1/1     Running   0             34s   io.kompose.service=mongodb-recommendation,pod-template-hash=55699465f7\nmongodb-reservation-5994859869-4m59j      1/1     Running   0             34s   io.kompose.service=mongodb-reservation,pod-template-hash=5994859869\nmongodb-user-969c6c449-2cdt2              1/1     Running   0             33s   io.kompose.service=mongodb-user,pod-template-hash=969c6c449\nprofile-8b6dd7c6c-57q4n                   1/1     Running   1 (20s ago)   35s   io.kompose.service=profile,pod-template-hash=8b6dd7c6c\nrate-7bdc978679-zkffp                     1/1     Running   1 (18s ago)   34s   io.kompose.service=rate,pod-template-hash=7bdc978679\nrecommendation-6879fb56bf-hnbz5           1/1     Running   1 (15s ago)   34s   io.kompose.service=recommendation,pod-template-hash=6879fb56bf\nreservation-78c9f7976b-5rfxh              1/1     Running   0             33s   io.kompose.service=reservation,pod-template-hash=78c9f7976b\nsearch-5c64c8f5bc-8gzg7                   1/1     Running   0             33s   io.kompose.service=search,pod-template-hash=5c64c8f5bc\nuser-66d5d6f874-vtqcb                     1/1     Running   1 (17s ago)   33s   io.kompose.service=user,pod-template-hash=66d5d6f874\nwrk2-job-f819b557-k4w7n                   1/1     Running   0             6s    batch.kubernetes.io/controller-uid=24741bef-e6aa-4fd8-86f1-e669f309eba9,batch.kubernetes.io/job-name=wrk2-job-f819b557,controller-uid=24741bef-e6aa-4fd8-86f1-e669f309eba9,job-name=wrk2-job-f819b557\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -o json | grep -E 'phase|containerStatuses'\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -o json | grep -E 'phase|containerStatuses'\")",
      "result": "                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n                \"containerStatuses\": [\n                \"phase\": \"Running\",\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl top nodes\")",
      "command": "exec_shell(\"kubectl top nodes\")",
      "result": "error: Metrics API not available\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get namespaces\")",
      "command": "exec_shell(\"kubectl get namespaces\")",
      "result": "NAME                              STATUS   AGE\nchaos-mesh                        Active   42m\ndefault                           Active   117m\nkube-node-lease                   Active   117m\nkube-public                       Active   117m\nkube-system                       Active   117m\nlocal-path-storage                Active   117m\nobserve                           Active   114m\nopenebs                           Active   114m\ntest-hotel-reservation-f819b557   Active   39s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe pod geo-84fbc958c7-zcfdf -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl describe pod geo-84fbc958c7-zcfdf -n test-hotel-reservation-f819b557\")",
      "result": "Error from server (NotFound): pods \"geo-84fbc958c7-zcfdf\" not found\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get events -n test-hotel-reservation --sort-by='.lastTimestamp'\")",
      "command": "exec_shell(\"kubectl get events -n test-hotel-reservation-f819b557 --sort-by='.lastTimestamp'\")",
      "result": "LAST SEEN   TYPE      REASON                  OBJECT                                         MESSAGE\n39s         Normal    SuccessfulCreate        replicaset/memcached-profile-668dcd6dbb        Created pod: memcached-profile-668dcd6dbb-xk8vx\n39s         Normal    WaitForFirstConsumer    persistentvolumeclaim/reservation-pvc          waiting for first consumer to be created before binding\n39s         Normal    Scheduled               pod/consul-78c8d79bb-qtch4                     Successfully assigned test-hotel-reservation-f819b557/consul-78c8d79bb-qtch4 to kind-worker\n39s         Normal    ScalingReplicaSet       deployment/mongodb-rate                        Scaled up replica set mongodb-rate-56cc8659c9 from 0 to 1\n39s         Normal    SuccessfulCreate        replicaset/consul-78c8d79bb                    Created pod: consul-78c8d79bb-qtch4\n39s         Normal    ScalingReplicaSet       deployment/consul                              Scaled up replica set consul-78c8d79bb from 0 to 1\n39s         Normal    Scheduled               pod/frontend-7fc7ddc9db-tp7km                  Successfully assigned test-hotel-reservation-f819b557/frontend-7fc7ddc9db-tp7km to kind-worker\n39s         Normal    SuccessfulCreate        replicaset/mongodb-rate-56cc8659c9             Created pod: mongodb-rate-56cc8659c9-t765c\n39s         Normal    ScalingReplicaSet       deployment/mongodb-profile                     Scaled up replica set mongodb-profile-758cb77f9f from 0 to 1\n39s         Normal    SuccessfulCreate        replicaset/mongodb-profile-758cb77f9f          Created pod: mongodb-profile-758cb77f9f-fb9r6\n39s         Normal    SuccessfulCreate        replicaset/frontend-7fc7ddc9db                 Created pod: frontend-7fc7ddc9db-tp7km\n39s         Normal    ScalingReplicaSet       deployment/frontend                            Scaled up replica set frontend-7fc7ddc9db from 0 to 1\n39s         Normal    Scheduled               pod/geo-84fbc958c7-h82gp                       Successfully assigned test-hotel-reservation-f819b557/geo-84fbc958c7-h82gp to kind-worker\n39s         Normal    Scheduled               pod/profile-8b6dd7c6c-57q4n                    Successfully assigned test-hotel-reservation-f819b557/profile-8b6dd7c6c-57q4n to kind-worker\n39s         Normal    WaitForFirstConsumer    persistentvolumeclaim/recommendation-pvc       waiting for first consumer to be created before binding\n39s         Normal    ScalingReplicaSet       deployment/mongodb-geo                         Scaled up replica set mongodb-geo-5ff578bcb8 from 0 to 1\n39s         Normal    SuccessfulCreate        replicaset/mongodb-geo-5ff578bcb8              Created pod: mongodb-geo-5ff578bcb8-kw94t\n39s         Normal    WaitForFirstConsumer    persistentvolumeclaim/rate-pvc                 waiting for first consumer to be created before binding\n39s         Normal    SuccessfulCreate        replicaset/profile-8b6dd7c6c                   Created pod: profile-8b6dd7c6c-57q4n\n39s         Normal    WaitForFirstConsumer    persistentvolumeclaim/user-pvc                 waiting for first consumer to be created before binding\n39s         Normal    WaitForFirstConsumer    persistentvolumeclaim/profile-pvc              waiting for first consumer to be created before binding\n39s         Normal    ExternalProvisioning    persistentvolumeclaim/profile-pvc              Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n39s         Normal    SuccessfulCreate        replicaset/geo-84fbc958c7                      Created pod: geo-84fbc958c7-h82gp\n39s         Normal    Provisioning            persistentvolumeclaim/rate-pvc                 External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/rate-pvc\"\n39s         Normal    WaitForFirstConsumer    persistentvolumeclaim/geo-pvc                  waiting for first consumer to be created before binding\n39s         Normal    Provisioning            persistentvolumeclaim/profile-pvc              External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/profile-pvc\"\n39s         Normal    Provisioning            persistentvolumeclaim/geo-pvc                  External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/geo-pvc\"\n39s         Normal    ScalingReplicaSet       deployment/profile                             Scaled up replica set profile-8b6dd7c6c from 0 to 1\n39s         Normal    ScalingReplicaSet       deployment/geo                                 Scaled up replica set geo-84fbc958c7 from 0 to 1\n39s         Normal    Scheduled               pod/jaeger-67445b6dd6-mz9dd                    Successfully assigned test-hotel-reservation-f819b557/jaeger-67445b6dd6-mz9dd to kind-worker\n39s         Normal    ScalingReplicaSet       deployment/memcached-rate                      Scaled up replica set memcached-rate-5b666ddfcb from 0 to 1\n39s         Normal    SuccessfulCreate        replicaset/memcached-rate-5b666ddfcb           Created pod: memcached-rate-5b666ddfcb-s4s9p\n39s         Normal    Scheduled               pod/memcached-rate-5b666ddfcb-s4s9p            Successfully assigned test-hotel-reservation-f819b557/memcached-rate-5b666ddfcb-s4s9p to kind-worker\n39s         Normal    SuccessfulCreate        replicaset/jaeger-67445b6dd6                   Created pod: jaeger-67445b6dd6-mz9dd\n39s         Normal    ScalingReplicaSet       deployment/jaeger                              Scaled up replica set jaeger-67445b6dd6 from 0 to 1\n39s         Normal    Scheduled               pod/memcached-profile-668dcd6dbb-xk8vx         Successfully assigned test-hotel-reservation-f819b557/memcached-profile-668dcd6dbb-xk8vx to kind-worker\n39s         Normal    ScalingReplicaSet       deployment/memcached-profile                   Scaled up replica set memcached-profile-668dcd6dbb from 0 to 1\n38s         Normal    ScalingReplicaSet       deployment/reservation                         Scaled up replica set reservation-78c9f7976b from 0 to 1\n38s         Normal    ScalingReplicaSet       deployment/memcached-reserve                   Scaled up replica set memcached-reserve-5bf87f5d54 from 0 to 1\n38s         Normal    SuccessfulCreate        replicaset/mongodb-recommendation-55699465f7   Created pod: mongodb-recommendation-55699465f7-f7d95\n38s         Normal    SuccessfulCreate        replicaset/mongodb-reservation-5994859869      Created pod: mongodb-reservation-5994859869-4m59j\n38s         Normal    ScalingReplicaSet       deployment/mongodb-reservation                 Scaled up replica set mongodb-reservation-5994859869 from 0 to 1\n38s         Normal    ScalingReplicaSet       deployment/recommendation                      Scaled up replica set recommendation-6879fb56bf from 0 to 1\n38s         Normal    Provisioning            persistentvolumeclaim/recommendation-pvc       External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/recommendation-pvc\"\n38s         Normal    SuccessfulCreate        replicaset/recommendation-6879fb56bf           Created pod: recommendation-6879fb56bf-hnbz5\n38s         Normal    ScalingReplicaSet       deployment/mongodb-recommendation              Scaled up replica set mongodb-recommendation-55699465f7 from 0 to 1\n38s         Normal    SuccessfulCreate        replicaset/rate-7bdc978679                     Created pod: rate-7bdc978679-zkffp\n38s         Normal    Scheduled               pod/memcached-reserve-5bf87f5d54-gbdxj         Successfully assigned test-hotel-reservation-f819b557/memcached-reserve-5bf87f5d54-gbdxj to kind-worker\n38s         Normal    ScalingReplicaSet       deployment/rate                                Scaled up replica set rate-7bdc978679 from 0 to 1\n38s         Normal    Scheduled               pod/recommendation-6879fb56bf-hnbz5            Successfully assigned test-hotel-reservation-f819b557/recommendation-6879fb56bf-hnbz5 to kind-worker\n38s         Normal    Scheduled               pod/rate-7bdc978679-zkffp                      Successfully assigned test-hotel-reservation-f819b557/rate-7bdc978679-zkffp to kind-worker\n38s         Normal    SuccessfulCreate        replicaset/memcached-reserve-5bf87f5d54        Created pod: memcached-reserve-5bf87f5d54-gbdxj\n37s         Normal    Scheduled               pod/search-5c64c8f5bc-8gzg7                    Successfully assigned test-hotel-reservation-f819b557/search-5c64c8f5bc-8gzg7 to kind-worker\n37s         Normal    ScalingReplicaSet       deployment/user                                Scaled up replica set user-66d5d6f874 from 0 to 1\n37s         Normal    SuccessfulCreate        replicaset/reservation-78c9f7976b              Created pod: reservation-78c9f7976b-5rfxh\n37s         Normal    Scheduled               pod/reservation-78c9f7976b-5rfxh               Successfully assigned test-hotel-reservation-f819b557/reservation-78c9f7976b-5rfxh to kind-worker\n37s         Normal    ScalingReplicaSet       deployment/search                              Scaled up replica set search-5c64c8f5bc from 0 to 1\n37s         Normal    Scheduled               pod/user-66d5d6f874-vtqcb                      Successfully assigned test-hotel-reservation-f819b557/user-66d5d6f874-vtqcb to kind-worker\n37s         Normal    SuccessfulCreate        replicaset/user-66d5d6f874                     Created pod: user-66d5d6f874-vtqcb\n37s         Normal    SuccessfulCreate        replicaset/mongodb-user-969c6c449              Created pod: mongodb-user-969c6c449-2cdt2\n37s         Normal    SuccessfulCreate        replicaset/search-5c64c8f5bc                   Created pod: search-5c64c8f5bc-8gzg7\n37s         Normal    ScalingReplicaSet       deployment/mongodb-user                        Scaled up replica set mongodb-user-969c6c449 from 0 to 1\n35s         Normal    Started                 pod/memcached-profile-668dcd6dbb-xk8vx         Started container hotel-reserv-profile-mmc\n35s         Normal    Pulled                  pod/frontend-7fc7ddc9db-tp7km                  Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n35s         Normal    Started                 pod/geo-84fbc958c7-h82gp                       Started container hotel-reserv-geo\n35s         Normal    Created                 pod/geo-84fbc958c7-h82gp                       Created container: hotel-reserv-geo\n35s         Normal    Pulled                  pod/geo-84fbc958c7-h82gp                       Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n35s         Normal    Created                 pod/jaeger-67445b6dd6-mz9dd                    Created container: hotel-reserv-jaeger\n35s         Normal    Pulled                  pod/jaeger-67445b6dd6-mz9dd                    Container image \"jaegertracing/all-in-one:1.57\" already present on machine\n35s         Normal    Started                 pod/frontend-7fc7ddc9db-tp7km                  Started container hotel-reserv-frontend\n35s         Normal    Created                 pod/frontend-7fc7ddc9db-tp7km                  Created container: hotel-reserv-frontend\n35s         Normal    Created                 pod/memcached-profile-668dcd6dbb-xk8vx         Created container: hotel-reserv-profile-mmc\n35s         Normal    Pulled                  pod/consul-78c8d79bb-qtch4                     Container image \"hashicorp/consul:latest\" already present on machine\n35s         Normal    Created                 pod/consul-78c8d79bb-qtch4                     Created container: consul\n35s         Normal    Started                 pod/jaeger-67445b6dd6-mz9dd                    Started container hotel-reserv-jaeger\n35s         Normal    Pulled                  pod/memcached-profile-668dcd6dbb-xk8vx         Container image \"memcached:1.6.7\" already present on machine\n35s         Normal    Started                 pod/consul-78c8d79bb-qtch4                     Started container consul\n34s         Normal    Started                 pod/memcached-rate-5b666ddfcb-s4s9p            Started container hotel-reserv-rate-mmc\n34s         Normal    Pulled                  pod/memcached-reserve-5bf87f5d54-gbdxj         Container image \"memcached:1.6.7\" already present on machine\n34s         Normal    Created                 pod/memcached-reserve-5bf87f5d54-gbdxj         Created container: hotel-reserv-reservation-mmc\n34s         Normal    Pulled                  pod/memcached-rate-5b666ddfcb-s4s9p            Container image \"memcached:1.6.7\" already present on machine\n34s         Normal    Created                 pod/memcached-rate-5b666ddfcb-s4s9p            Created container: hotel-reserv-rate-mmc\n33s         Normal    Pulled                  pod/search-5c64c8f5bc-8gzg7                    Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n33s         Normal    Started                 pod/reservation-78c9f7976b-5rfxh               Started container hotel-reserv-reservation\n33s         Normal    Created                 pod/reservation-78c9f7976b-5rfxh               Created container: hotel-reserv-reservation\n33s         Normal    Pulled                  pod/reservation-78c9f7976b-5rfxh               Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n33s         Normal    Started                 pod/memcached-reserve-5bf87f5d54-gbdxj         Started container hotel-reserv-reservation-mmc\n33s         Normal    Started                 pod/search-5c64c8f5bc-8gzg7                    Started container hotel-reserv-search\n33s         Normal    Created                 pod/search-5c64c8f5bc-8gzg7                    Created container: hotel-reserv-search\n32s         Normal    ExternalProvisioning    persistentvolumeclaim/recommendation-pvc       Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n32s         Normal    ExternalProvisioning    persistentvolumeclaim/rate-pvc                 Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n32s         Normal    ExternalProvisioning    persistentvolumeclaim/user-pvc                 Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n32s         Normal    ExternalProvisioning    persistentvolumeclaim/geo-pvc                  Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n32s         Normal    ProvisioningSucceeded   persistentvolumeclaim/profile-pvc              Successfully provisioned volume pvc-96b3bdbd-08e8-450b-8194-f39f67e80d1c\n32s         Normal    ExternalProvisioning    persistentvolumeclaim/reservation-pvc          Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n31s         Normal    Scheduled               pod/mongodb-profile-758cb77f9f-fb9r6           Successfully assigned test-hotel-reservation-f819b557/mongodb-profile-758cb77f9f-fb9r6 to kind-worker\n31s         Normal    Created                 pod/mongodb-profile-758cb77f9f-fb9r6           Created container: hotel-reserv-profile-mongo\n31s         Normal    Provisioning            persistentvolumeclaim/reservation-pvc          External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/reservation-pvc\"\n31s         Normal    Pulled                  pod/mongodb-profile-758cb77f9f-fb9r6           Container image \"mongo:4.4.6\" already present on machine\n30s         Normal    ProvisioningSucceeded   persistentvolumeclaim/rate-pvc                 Successfully provisioned volume pvc-ca82b26d-7f8d-4f31-82ef-54a1543e1473\n30s         Normal    Started                 pod/mongodb-profile-758cb77f9f-fb9r6           Started container hotel-reserv-profile-mongo\n30s         Normal    Scheduled               pod/mongodb-rate-56cc8659c9-t765c              Successfully assigned test-hotel-reservation-f819b557/mongodb-rate-56cc8659c9-t765c to kind-worker\n29s         Normal    Created                 pod/mongodb-rate-56cc8659c9-t765c              Created container: hotel-reserv-rate-mongo\n29s         Normal    Provisioning            persistentvolumeclaim/user-pvc                 External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/user-pvc\"\n29s         Normal    Started                 pod/mongodb-rate-56cc8659c9-t765c              Started container hotel-reserv-rate-mongo\n29s         Normal    Pulled                  pod/mongodb-rate-56cc8659c9-t765c              Container image \"mongo:4.4.6\" already present on machine\n29s         Normal    ProvisioningSucceeded   persistentvolumeclaim/geo-pvc                  Successfully provisioned volume pvc-abab6a4f-d4f6-4228-a30e-31ab70a4d21a\n28s         Normal    ProvisioningSucceeded   persistentvolumeclaim/recommendation-pvc       Successfully provisioned volume pvc-1475f7a5-03d6-4bc5-aa5c-a7c23eb254a4\n28s         Normal    Scheduled               pod/mongodb-geo-5ff578bcb8-kw94t               Successfully assigned test-hotel-reservation-f819b557/mongodb-geo-5ff578bcb8-kw94t to kind-worker\n27s         Normal    Pulled                  pod/mongodb-geo-5ff578bcb8-kw94t               Container image \"mongo:4.4.6\" already present on machine\n27s         Normal    Created                 pod/mongodb-geo-5ff578bcb8-kw94t               Created container: hotel-reserv-geo-mongo\n27s         Normal    Scheduled               pod/mongodb-recommendation-55699465f7-f7d95    Successfully assigned test-hotel-reservation-f819b557/mongodb-recommendation-55699465f7-f7d95 to kind-worker\n26s         Normal    Pulled                  pod/mongodb-recommendation-55699465f7-f7d95    Container image \"mongo:4.4.6\" already present on machine\n26s         Normal    Scheduled               pod/mongodb-reservation-5994859869-4m59j       Successfully assigned test-hotel-reservation-f819b557/mongodb-reservation-5994859869-4m59j to kind-worker\n26s         Normal    Started                 pod/mongodb-recommendation-55699465f7-f7d95    Started container hotel-reserv-recommendation-mongo\n26s         Normal    Started                 pod/mongodb-geo-5ff578bcb8-kw94t               Started container hotel-reserv-geo-mongo\n26s         Normal    ProvisioningSucceeded   persistentvolumeclaim/reservation-pvc          Successfully provisioned volume pvc-fbc13203-ee84-41fa-a538-a8b754d43a43\n26s         Normal    Created                 pod/mongodb-recommendation-55699465f7-f7d95    Created container: hotel-reserv-recommendation-mongo\n25s         Normal    Pulled                  pod/mongodb-reservation-5994859869-4m59j       Container image \"mongo:4.4.6\" already present on machine\n25s         Normal    Created                 pod/mongodb-reservation-5994859869-4m59j       Created container: hotel-reserv-reservation-mongo\n24s         Normal    Started                 pod/profile-8b6dd7c6c-57q4n                    Started container hotel-reserv-profile\n24s         Normal    Created                 pod/profile-8b6dd7c6c-57q4n                    Created container: hotel-reserv-profile\n24s         Normal    Pulled                  pod/profile-8b6dd7c6c-57q4n                    Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n24s         Normal    Started                 pod/mongodb-reservation-5994859869-4m59j       Started container hotel-reserv-reservation-mongo\n23s         Normal    ProvisioningSucceeded   persistentvolumeclaim/user-pvc                 Successfully provisioned volume pvc-d7b1e73b-25d9-48f6-a3e3-fd2e6eba7776\n23s         Normal    Scheduled               pod/mongodb-user-969c6c449-2cdt2               Successfully assigned test-hotel-reservation-f819b557/mongodb-user-969c6c449-2cdt2 to kind-worker\n22s         Normal    Created                 pod/mongodb-user-969c6c449-2cdt2               Created container: hotel-reserv-user-mongo\n22s         Normal    Started                 pod/mongodb-user-969c6c449-2cdt2               Started container hotel-reserv-user-mongo\n22s         Normal    Pulled                  pod/mongodb-user-969c6c449-2cdt2               Container image \"mongo:4.4.6\" already present on machine\n21s         Normal    Pulled                  pod/rate-7bdc978679-zkffp                      Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n21s         Normal    Started                 pod/rate-7bdc978679-zkffp                      Started container hotel-reserv-rate\n21s         Normal    Created                 pod/rate-7bdc978679-zkffp                      Created container: hotel-reserv-rate\n20s         Normal    Pulled                  pod/user-66d5d6f874-vtqcb                      Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n20s         Normal    Created                 pod/user-66d5d6f874-vtqcb                      Created container: hotel-reserv-user\n20s         Normal    Started                 pod/user-66d5d6f874-vtqcb                      Started container hotel-reserv-user\n18s         Normal    Started                 pod/recommendation-6879fb56bf-hnbz5            Started container hotel-reserv-recommendation\n18s         Normal    Pulled                  pod/recommendation-6879fb56bf-hnbz5            Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n18s         Normal    Scheduled               pod/geo-84fbc958c7-v9jpp                       Successfully assigned test-hotel-reservation-f819b557/geo-84fbc958c7-v9jpp to kind-worker\n18s         Normal    Killing                 pod/geo-84fbc958c7-h82gp                       Stopping container hotel-reserv-geo\n18s         Normal    Created                 pod/recommendation-6879fb56bf-hnbz5            Created container: hotel-reserv-recommendation\n18s         Normal    SuccessfulCreate        replicaset/geo-84fbc958c7                      Created pod: geo-84fbc958c7-v9jpp\n17s         Normal    Killing                 pod/mongodb-geo-5ff578bcb8-kw94t               Stopping container hotel-reserv-geo-mongo\n17s         Normal    SuccessfulCreate        replicaset/mongodb-geo-5ff578bcb8              Created pod: mongodb-geo-5ff578bcb8-k5hd4\n17s         Normal    Scheduled               pod/mongodb-geo-5ff578bcb8-k5hd4               Successfully assigned test-hotel-reservation-f819b557/mongodb-geo-5ff578bcb8-k5hd4 to kind-worker\n16s         Normal    Created                 pod/mongodb-geo-5ff578bcb8-k5hd4               Created container: hotel-reserv-geo-mongo\n16s         Normal    Started                 pod/geo-84fbc958c7-v9jpp                       Started container hotel-reserv-geo\n16s         Normal    Created                 pod/geo-84fbc958c7-v9jpp                       Created container: hotel-reserv-geo\n16s         Normal    Pulled                  pod/geo-84fbc958c7-v9jpp                       Container image \"yinfangchen/hotelreservation:latest\" already present on machine\n16s         Normal    Started                 pod/mongodb-geo-5ff578bcb8-k5hd4               Started container hotel-reserv-geo-mongo\n16s         Normal    Pulled                  pod/mongodb-geo-5ff578bcb8-k5hd4               Container image \"mongo:4.4.6\" already present on machine\n10s         Warning   BackOff                 pod/geo-84fbc958c7-v9jpp                       Back-off restarting failed container hotel-reserv-geo in pod geo-84fbc958c7-v9jpp_test-hotel-reservation-f819b557(3a6acbd4-282e-4209-865e-b59fcdd95270)\n10s         Normal    Pulled                  pod/wrk2-job-f819b557-k4w7n                    Container image \"deathstarbench/wrk2-client:latest\" already present on machine\n10s         Normal    Created                 pod/wrk2-job-f819b557-k4w7n                    Created container: wrk2\n10s         Normal    Started                 pod/wrk2-job-f819b557-k4w7n                    Started container wrk2\n10s         Normal    Scheduled               pod/wrk2-job-f819b557-k4w7n                    Successfully assigned test-hotel-reservation-f819b557/wrk2-job-f819b557-k4w7n to kind-worker\n10s         Normal    SuccessfulCreate        job/wrk2-job-f819b557                          Created pod: wrk2-job-f819b557-k4w7n\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get events -n test-hotel-reservation --field-selector involvedObject.name=geo-84fbc958c7-zcfdf\")",
      "command": "exec_shell(\"kubectl get events -n test-hotel-reservation-f819b557 --field-selector involvedObject.name=geo-84fbc958c7-zcfdf\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl logs geo-84fbc958c7-zcfdf -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl logs geo-84fbc958c7-zcfdf -n test-hotel-reservation-f819b557\")",
      "result": "error: error from server (NotFound): pods \"geo-84fbc958c7-zcfdf\" not found in namespace \"test-hotel-reservation-f819b557\"\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl logs geo-84fbc958c7-zcfdf -n test-hotel-reservation --previous\")",
      "command": "exec_shell(\"kubectl logs geo-84fbc958c7-zcfdf -n test-hotel-reservation-f819b557 --previous\")",
      "result": "error: error from server (NotFound): pods \"geo-84fbc958c7-zcfdf\" not found in namespace \"test-hotel-reservation-f819b557\"\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl logs geo-84fbc958c7-zcfdf -n test-hotel-reservation --tail=100\")",
      "command": "exec_shell(\"kubectl logs geo-84fbc958c7-zcfdf -n test-hotel-reservation-f819b557 --tail=100\")",
      "result": "error: error from server (NotFound): pods \"geo-84fbc958c7-zcfdf\" not found in namespace \"test-hotel-reservation-f819b557\"\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation -o yaml\")",
      "command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation-f819b557 -o yaml\")",
      "result": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: \"1\"\n    kompose.cmd: kompose convert\n    kompose.version: 1.22.0 (955b78124)\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"annotations\":{\"kompose.cmd\":\"kompose convert\",\"kompose.version\":\"1.22.0 (955b78124)\"},\"creationTimestamp\":null,\"labels\":{\"io.kompose.service\":\"geo\"},\"name\":\"geo\",\"namespace\":\"test-hotel-reservation-f819b557\"},\"spec\":{\"replicas\":1,\"selector\":{\"matchLabels\":{\"io.kompose.service\":\"geo\"}},\"strategy\":{},\"template\":{\"metadata\":{\"annotations\":{\"kompose.cmd\":\"kompose convert\",\"kompose.version\":\"1.22.0 (955b78124)\",\"sidecar.istio.io/statsInclusionPrefixes\":\"cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\",\"sidecar.istio.io/statsInclusionRegexps\":\"http.*\"},\"creationTimestamp\":null,\"labels\":{\"io.kompose.service\":\"geo\"}},\"spec\":{\"containers\":[{\"command\":[\"geo\"],\"env\":[{\"name\":\"JAEGER_SAMPLE_RATIO\",\"value\":\"1\"}],\"image\":\"yinfangchen/hotelreservation:latest\",\"imagePullPolicy\":\"IfNotPresent\",\"name\":\"hotel-reserv-geo\",\"ports\":[{\"containerPort\":8083}],\"resources\":{\"limits\":{\"cpu\":\"1000m\"},\"requests\":{\"cpu\":\"100m\"}}}],\"restartPolicy\":\"Always\"}}},\"status\":{}}\n  creationTimestamp: \"2025-12-24T10:17:19Z\"\n  generation: 1\n  labels:\n    io.kompose.service: geo\n  name: geo\n  namespace: test-hotel-reservation-f819b557\n  resourceVersion: \"73814\"\n  uid: 3071f6da-cc98-448f-8592-ce58e209d619\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      io.kompose.service: geo\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kompose.cmd: kompose convert\n        kompose.version: 1.22.0 (955b78124)\n        sidecar.istio.io/statsInclusionPrefixes: cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\n        sidecar.istio.io/statsInclusionRegexps: http.*\n      creationTimestamp: null\n      labels:\n        io.kompose.service: geo\n    spec:\n      containers:\n      - command:\n        - geo\n        env:\n        - name: JAEGER_SAMPLE_RATIO\n          value: \"1\"\n        image: yinfangchen/hotelreservation:latest\n        imagePullPolicy: IfNotPresent\n        name: hotel-reserv-geo\n        ports:\n        - containerPort: 8083\n          protocol: TCP\n        resources:\n          limits:\n            cpu: \"1\"\n          requests:\n            cpu: 100m\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\nstatus:\n  conditions:\n  - lastTransitionTime: \"2025-12-24T10:17:19Z\"\n    lastUpdateTime: \"2025-12-24T10:17:24Z\"\n    message: ReplicaSet \"geo-84fbc958c7\" has successfully progressed.\n    reason: NewReplicaSetAvailable\n    status: \"True\"\n    type: Progressing\n  - lastTransitionTime: \"2025-12-24T10:17:48Z\"\n    lastUpdateTime: \"2025-12-24T10:17:48Z\"\n    message: Deployment does not have minimum availability.\n    reason: MinimumReplicasUnavailable\n    status: \"False\"\n    type: Available\n  observedGeneration: 1\n  replicas: 1\n  unavailableReplicas: 1\n  updatedReplicas: 1\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation -o json | grep -E 'image|command|args'\")",
      "command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation-f819b557 -o json | grep -E 'image|command|args'\")",
      "result": "            \"kubectl.kubernetes.io/last-applied-configuration\": \"{\\\"apiVersion\\\":\\\"apps/v1\\\",\\\"kind\\\":\\\"Deployment\\\",\\\"metadata\\\":{\\\"annotations\\\":{\\\"kompose.cmd\\\":\\\"kompose convert\\\",\\\"kompose.version\\\":\\\"1.22.0 (955b78124)\\\"},\\\"creationTimestamp\\\":null,\\\"labels\\\":{\\\"io.kompose.service\\\":\\\"geo\\\"},\\\"name\\\":\\\"geo\\\",\\\"namespace\\\":\\\"test-hotel-reservation-f819b557\\\"},\\\"spec\\\":{\\\"replicas\\\":1,\\\"selector\\\":{\\\"matchLabels\\\":{\\\"io.kompose.service\\\":\\\"geo\\\"}},\\\"strategy\\\":{},\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"kompose.cmd\\\":\\\"kompose convert\\\",\\\"kompose.version\\\":\\\"1.22.0 (955b78124)\\\",\\\"sidecar.istio.io/statsInclusionPrefixes\\\":\\\"cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\\\",\\\"sidecar.istio.io/statsInclusionRegexps\\\":\\\"http.*\\\"},\\\"creationTimestamp\\\":null,\\\"labels\\\":{\\\"io.kompose.service\\\":\\\"geo\\\"}},\\\"spec\\\":{\\\"containers\\\":[{\\\"command\\\":[\\\"geo\\\"],\\\"env\\\":[{\\\"name\\\":\\\"JAEGER_SAMPLE_RATIO\\\",\\\"value\\\":\\\"1\\\"}],\\\"image\\\":\\\"yinfangchen/hotelreservation:latest\\\",\\\"imagePullPolicy\\\":\\\"IfNotPresent\\\",\\\"name\\\":\\\"hotel-reserv-geo\\\",\\\"ports\\\":[{\\\"containerPort\\\":8083}],\\\"resources\\\":{\\\"limits\\\":{\\\"cpu\\\":\\\"1000m\\\"},\\\"requests\\\":{\\\"cpu\\\":\\\"100m\\\"}}}],\\\"restartPolicy\\\":\\\"Always\\\"}}},\\\"status\\\":{}}\\n\"\n                        \"command\": [\n                        \"image\": \"yinfangchen/hotelreservation:latest\",\n                        \"imagePullPolicy\": \"IfNotPresent\",\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get replicaset -n test-hotel-reservation -l io.kompose.service=geo\")",
      "command": "exec_shell(\"kubectl get replicaset -n test-hotel-reservation-f819b557 -l io.kompose.service=geo\")",
      "result": "NAME             DESIRED   CURRENT   READY   AGE\ngeo-84fbc958c7   1         1         0       44s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe replicaset geo-84fbc958c7 -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl describe replicaset geo-84fbc958c7 -n test-hotel-reservation-f819b557\")",
      "result": "Name:           geo-84fbc958c7\nNamespace:      test-hotel-reservation-f819b557\nSelector:       io.kompose.service=geo,pod-template-hash=84fbc958c7\nLabels:         io.kompose.service=geo\n                pod-template-hash=84fbc958c7\nAnnotations:    deployment.kubernetes.io/desired-replicas: 1\n                deployment.kubernetes.io/max-replicas: 2\n                deployment.kubernetes.io/revision: 1\n                kompose.cmd: kompose convert\n                kompose.version: 1.22.0 (955b78124)\nControlled By:  Deployment/geo\nReplicas:       1 current / 1 desired\nPods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:       io.kompose.service=geo\n                pod-template-hash=84fbc958c7\n  Annotations:  kompose.cmd: kompose convert\n                kompose.version: 1.22.0 (955b78124)\n                sidecar.istio.io/statsInclusionPrefixes:\n                  cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\n                sidecar.istio.io/statsInclusionRegexps: http.*\n  Containers:\n   hotel-reserv-geo:\n    Image:      yinfangchen/hotelreservation:latest\n    Port:       8083/TCP\n    Host Port:  0/TCP\n    Command:\n      geo\n    Limits:\n      cpu:  1\n    Requests:\n      cpu:  100m\n    Environment:\n      JAEGER_SAMPLE_RATIO:  1\n    Mounts:                 <none>\n  Volumes:                  <none>\n  Node-Selectors:           <none>\n  Tolerations:              <none>\nEvents:\n  Type    Reason            Age   From                   Message\n  ----    ------            ----  ----                   -------\n  Normal  SuccessfulCreate  45s   replicaset-controller  Created pod: geo-84fbc958c7-h82gp\n  Normal  SuccessfulCreate  24s   replicaset-controller  Created pod: geo-84fbc958c7-v9jpp\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get configmap -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get configmap -n test-hotel-reservation-f819b557\")",
      "result": "NAME                           DATA   AGE\nfailure-admin-geo              4      47s\nfailure-admin-rate             4      47s\nkube-root-ca.crt               1      47s\nmongo-geo-script               1      47s\nmongo-rate-script              1      47s\nwrk2-payload-script-f819b557   1      16s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get secret -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get secret -n test-hotel-reservation-f819b557\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe configmap -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl describe configmap -n test-hotel-reservation-f819b557\")",
      "result": "Name:         failure-admin-geo\nNamespace:    test-hotel-reservation-f819b557\nLabels:       <none>\nAnnotations:  <none>\n\nData\n====\nremove-admin-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nROOT_USER=\"root\"\nROOT_PWD=\"root\" \n\necho \"Removing admin user...\"\n\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.dropUser('admin');\"\n\necho \"Admin user removed successfully\"\n\n\nremove-mitigate-admin-geo-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nROOT_USER=\"root\"\nROOT_PWD=\"root\"  \n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"  \nREAD_WRITE_ROLE=\"readWrite\"\nTARGET_DB=\"geo-db\"\n\necho \"Recreating admin user...\"\n\n# Connect to MongoDB and create the admin user\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.createUser({user: '$ADMIN_USER', pwd: '$ADMIN_PWD', roles:[{role:'userAdminAnyDatabase',db:'admin'}]});\"\n\necho \"Admin user recreated\"\n\n# Grant readWrite role on the target database\necho \"Granting readWrite role to $ADMIN_USER on $TARGET_DB database...\"\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ADMIN_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\necho \"Privileges restored successfully\"\n\n\nrevoke-admin-geo-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"\n# TARGET_DB=\"rate-db\"\nTARGET_DB=\"geo-db\"\n\necho \"Downgrading admin user privileges...\"\n\n# Connect to MongoDB and revoke roles\nmongo admin -u $ADMIN_USER -p $ADMIN_PWD --authenticationDatabase admin \\\n     --eval \"db.revokeRolesFromUser('$ADMIN_USER', [{role: 'readWrite', db: '$TARGET_DB'}]);\"\n\necho \"Privileges downgraded\"\n\n\nrevoke-mitigate-admin-geo-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"\n\n# TARGET_DB=\"rate-db\"\nTARGET_DB=\"geo-db\"\nREAD_WRITE_ROLE=\"readWrite\"\n\necho \"Restoring readWrite privilege to the $ADMIN_USER user for the $TARGET_DB database...\"\n\n# Grant readWrite role on the target database\nmongo admin -u $ADMIN_USER -p $ADMIN_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ADMIN_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\necho \"Privilege restored successfully\"\n\n\nBinaryData\n====\n\nEvents:  <none>\n\n\nName:         failure-admin-rate\nNamespace:    test-hotel-reservation-f819b557\nLabels:       <none>\nAnnotations:  <none>\n\nData\n====\nremove-admin-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nROOT_USER=\"root\"\nROOT_PWD=\"root\" \n\necho \"Removing admin user...\"\n\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.dropUser('admin');\"\n\necho \"Admin user removed successfully\"\n\n\nremove-mitigate-admin-rate-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nROOT_USER=\"root\"\nROOT_PWD=\"root\"  \n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"  \nREAD_WRITE_ROLE=\"readWrite\"\nTARGET_DB=\"rate-db\"\n# TARGET_DB=\"geo-db\"\n\necho \"Recreating admin user...\"\n\n# Connect to MongoDB and create the admin user\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.createUser({user: '$ADMIN_USER', pwd: '$ADMIN_PWD', roles:[{role:'userAdminAnyDatabase',db:'admin'}]});\"\n\necho \"Admin user recreated\"\n\n# Grant readWrite role on the target database\necho \"Granting readWrite role to $ADMIN_USER on $TARGET_DB database...\"\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ADMIN_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\necho \"Privileges restored successfully\"\n\n\nrevoke-admin-rate-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"\nTARGET_DB=\"rate-db\"\n# TARGET_DB=\"geo-db\"\n\necho \"Downgrading admin user privileges...\"\n\n# Connect to MongoDB and revoke roles\nmongo admin -u $ADMIN_USER -p $ADMIN_PWD --authenticationDatabase admin \\\n     --eval \"db.revokeRolesFromUser('$ADMIN_USER', [{role: 'readWrite', db: '$TARGET_DB'}]);\"\n\necho \"Privileges downgraded\"\n\n\nrevoke-mitigate-admin-rate-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"\n\nTARGET_DB=\"rate-db\"\n# TARGET_DB=\"geo-db\"\nREAD_WRITE_ROLE=\"readWrite\"\n\necho \"Restoring readWrite privilege to the $ADMIN_USER user for the $TARGET_DB database...\"\n\n# Grant readWrite role on the target database\nmongo admin -u $ADMIN_USER -p $ADMIN_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ADMIN_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\necho \"Privilege restored successfully\"\n\n\nBinaryData\n====\n\nEvents:  <none>\n\n\nName:         kube-root-ca.crt\nNamespace:    test-hotel-reservation-f819b557\nLabels:       <none>\nAnnotations:  kubernetes.io/description:\n                Contains a CA bundle that can be used to verify the kube-apiserver when using internal endpoints such as the internal service IP or kubern...\n\nData\n====\nca.crt:\n----\n-----BEGIN CERTIFICATE-----\nMIIDBTCCAe2gAwIBAgIIJ8v64PognAswDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczAeFw0yNTEyMjQwODE1MDlaFw0zNTEyMjIwODIwMDlaMBUx\nEzARBgNVBAMTCmt1YmVybmV0ZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQDEbBrgTQL167C/01MWewFEoJcuZGzavvkLm2W4BNJmrYtfLiB0DGgGElmY\nHAMK9iJ5fxhBD1jsgTx5EnxhQ226lQcVRWw6ApF+yzVrdYrfNVOcoa+VCHzN6AEa\nwd68MfSQHcDXew9yU3r5xhMgruD1ZJT+W/hToqvhYmwzGqpZqVqeYidyIX4rCkWJ\nznd5iSMDFzP0HHfjyI38IdC58pPBAZ4tSryCauODOYkjEJMr3Um2uPHwM1Jkcb4k\nlZVBgvQxPs8nqrMaCIAOiBzN47xUnIAlB6voMYdIHJDdFqwfYrM7A09eYetwbhWo\nSKZQUodj2JdNoUyCWoX0cRy8/UAlAgMBAAGjWTBXMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBR6JSVN0yITs9zYI2XfWR9aJIPRADAV\nBgNVHREEDjAMggprdWJlcm5ldGVzMA0GCSqGSIb3DQEBCwUAA4IBAQC4H3ycXavW\nchSesh3j09utAflSIDCxPy8pPjFVzFyxoQJLJ/IqfMiPX1Wa0nB8f6UNYtKZEebY\nzyQfQeB+kl11CLapEYW2ZDO5gpyskUH96mipTybL8KRzX6hazBtwm5vcRmb3pVJe\nkYeysEB7oFNpMW09oZ20+Q5FB7E4rwEnk2fI0WkVPHqk8NuZ9ZpKg1KVxMg5XD6T\nUeRglbQoLp07Z+gG8cxB0l8k/spPKZ7EOtENMCd28qB7RuALe9ZQDb7XBsgOmw8v\nD7JxOAq+W4hCTWnGtCzBcdT2Jb/Sm0tNbeYxiLFFhWdjcaAxDReN/mBYyckofoNm\nNYjQ/aVouOT8\n-----END CERTIFICATE-----\n\n\n\nBinaryData\n====\n\nEvents:  <none>\n\n\nName:         mongo-geo-script\nNamespace:    test-hotel-reservation-f819b557\nLabels:       <none>\nAnnotations:  <none>\n\nData\n====\nk8s-geo-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"\n\nROOT_USER=\"root\"\nROOT_PWD=\"root\"\n\nTARGET_DB=\"geo-db\"\nREAD_WRITE_ROLE=\"readWrite\"\n\necho \"Waiting for MongoDB to start...\"\nuntil mongo --eval \"print('waited for connection')\" > /dev/null 2>&1; do\n  sleep 1\ndone\necho \"MongoDB started\"\n\n# Create the admin user (will fail if the user already exists)\necho \"Creating admin user...\"\nmongo admin --eval \"db.createUser({user: '$ADMIN_USER', pwd: '$ADMIN_PWD', roles:[{role:'userAdminAnyDatabase',db:'admin'}]});\"\n\n# Grant readWrite role on the target database\necho \"Granting readWrite role to $ADMIN_USER on $TARGET_DB database...\"\nmongo admin -u $ADMIN_USER -p $ADMIN_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ADMIN_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\n# Create the root user (will fail if the user already exists)\necho \"Creating root user...\"\nmongo admin --eval \"db.createUser({user: '$ROOT_USER', pwd: '$ROOT_PWD', roles:[{role:'userAdminAnyDatabase',db:'admin'}]});\"\n\n# Grant readWrite role on the target database to root\necho \"Granting readWrite role to $ROOT_USER on $TARGET_DB database...\"\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ROOT_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\n\necho \"Initialization script completed\"\n\n\nBinaryData\n====\n\nEvents:  <none>\n\n\nName:         mongo-rate-script\nNamespace:    test-hotel-reservation-f819b557\nLabels:       <none>\nAnnotations:  <none>\n\nData\n====\nk8s-rate-mongo.sh:\n----\n#!/bin/bash\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\n\nADMIN_USER=\"admin\"\nADMIN_PWD=\"admin\"\n\nROOT_USER=\"root\"\nROOT_PWD=\"root\"\n\nTARGET_DB=\"rate-db\"\nREAD_WRITE_ROLE=\"readWrite\"\n\necho \"Waiting for MongoDB to start...\"\nuntil mongo --eval \"print('waited for connection')\" > /dev/null 2>&1; do\n  sleep 1\ndone\necho \"MongoDB started\"\n\n# Create the admin user (will fail if the user already exists)\necho \"Creating admin user...\"\nmongo admin --eval \"db.createUser({user: '$ADMIN_USER', pwd: '$ADMIN_PWD', roles:[{role:'userAdminAnyDatabase',db:'admin'}]});\"\n\n# Grant readWrite role on the target database\necho \"Granting readWrite role to $ADMIN_USER on $TARGET_DB database...\"\nmongo admin -u $ADMIN_USER -p $ADMIN_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ADMIN_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\n# Create the root user (will fail if the user already exists)\necho \"Creating root user...\"\nmongo admin --eval \"db.createUser({user: '$ROOT_USER', pwd: '$ROOT_PWD', roles:[{role:'userAdminAnyDatabase',db:'admin'}]});\"\n\n# Grant readWrite role on the target database to root\necho \"Granting readWrite role to $ROOT_USER on $TARGET_DB database...\"\nmongo admin -u $ROOT_USER -p $ROOT_PWD --authenticationDatabase admin \\\n     --eval \"db.grantRolesToUser('$ROOT_USER', [{role: '$READ_WRITE_ROLE', db: '$TARGET_DB'}]);\"\n\n\necho \"Initialization script completed\"\n\n\nBinaryData\n====\n\nEvents:  <none>\n\n\nName:         wrk2-payload-script-f819b557\nNamespace:    test-hotel-reservation-f819b557\nLabels:       <none>\nAnnotations:  <none>\n\nData\n====\nmixed-workload_type_1.lua:\n----\nlocal socket = require(\"socket\")\nmath.randomseed(socket.gettime()*1000)\nmath.random(); math.random(); math.random()\n\nlocal url = \"http://localhost:5000\"\n\nlocal function get_user()\n  local id = math.random(0, 500)\n  local user_name = \"Cornell_\" .. tostring(id)\n  local pass_word = \"\"\n  for i = 0, 9, 1 do \n    pass_word = pass_word .. tostring(id)\n  end\n  return user_name, pass_word\nend\n\nlocal function search_hotel() \n  local in_date = math.random(9, 23)\n  local out_date = math.random(in_date + 1, 24)\n\n  local in_date_str = tostring(in_date)\n  if in_date <= 9 then\n    in_date_str = \"2015-04-0\" .. in_date_str \n  else\n    in_date_str = \"2015-04-\" .. in_date_str\n  end\n\n  local out_date_str = tostring(out_date)\n  if out_date <= 9 then\n    out_date_str = \"2015-04-0\" .. out_date_str \n  else\n    out_date_str = \"2015-04-\" .. out_date_str\n  end\n\n  local lat = 38.0235 + (math.random(0, 481) - 240.5)/1000.0\n  local lon = -122.095 + (math.random(0, 325) - 157.0)/1000.0\n\n  local method = \"GET\"\n  local path = url .. \"/hotels?inDate=\" .. in_date_str .. \n    \"&outDate=\" .. out_date_str .. \"&lat=\" .. tostring(lat) .. \"&lon=\" .. tostring(lon)\n\n  local headers = {}\n  -- headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n  return wrk.format(method, path, headers, nil)\nend\n\nlocal function recommend()\n  local coin = math.random()\n  local req_param = \"\"\n  if coin < 0.33 then\n    req_param = \"dis\"\n  elseif coin < 0.66 then\n    req_param = \"rate\"\n  else\n    req_param = \"price\"\n  end\n\n  local lat = 38.0235 + (math.random(0, 481) - 240.5)/1000.0\n  local lon = -122.095 + (math.random(0, 325) - 157.0)/1000.0\n\n  local method = \"GET\"\n  local path = url .. \"/recommendations?require=\" .. req_param .. \n    \"&lat=\" .. tostring(lat) .. \"&lon=\" .. tostring(lon)\n  local headers = {}\n  -- headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n  return wrk.format(method, path, headers, nil)\nend\n\nlocal function reserve()\n  local in_date = math.random(9, 23)\n  local out_date = in_date + math.random(1, 5)\n\n  local in_date_str = tostring(in_date)\n  if in_date <= 9 then\n    in_date_str = \"2015-04-0\" .. in_date_str \n  else\n    in_date_str = \"2015-04-\" .. in_date_str\n  end\n\n  local out_date_str = tostring(out_date)\n  if out_date <= 9 then\n    out_date_str = \"2015-04-0\" .. out_date_str \n  else\n    out_date_str = \"2015-04-\" .. out_date_str\n  end\n\n  local hotel_id = tostring(math.random(1, 80))\n  local user_id, password = get_user()\n  local cust_name = user_id\n\n  local num_room = \"1\"\n\n  local method = \"POST\"\n  local path = url .. \"/reservation?inDate=\" .. in_date_str .. \n    \"&outDate=\" .. out_date_str .. \"&lat=\" .. tostring(lat) .. \"&lon=\" .. tostring(lon) ..\n    \"&hotelId=\" .. hotel_id .. \"&customerName=\" .. cust_name .. \"&username=\" .. user_id ..\n    \"&password=\" .. password .. \"&number=\" .. num_room\n  local headers = {}\n  -- headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n  return wrk.format(method, path, headers, nil)\nend\n\nlocal function user_login()\n  local user_name, password = get_user()\n  local method = \"POST\"\n  local path = url .. \"/user?username=\" .. user_name .. \"&password=\" .. password\n  local headers = {}\n  -- headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n  return wrk.format(method, path, headers, nil)\nend\n\nrequest = function()\n  cur_time = math.floor(socket.gettime())\n  local search_ratio      = 0.6\n  local recommend_ratio   = 0.39\n  local user_ratio        = 0.005\n  local reserve_ratio     = 0.005\n\n  local coin = math.random()\n  if coin < search_ratio then\n    return search_hotel(url)\n  elseif coin < search_ratio + recommend_ratio then\n    return recommend(url)\n  elseif coin < search_ratio + recommend_ratio + user_ratio then\n    return user_login(url)\n  else \n    return reserve(url)\n  end\nend\n\n\n\nBinaryData\n====\n\nEvents:  <none>\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation -o jsonpath='{.spec.template.spec.containers[*].env}'\")",
      "command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation-f819b557 -o jsonpath='{.spec.template.spec.containers[*].env}'\")",
      "result": "[{\"name\":\"JAEGER_SAMPLE_RATIO\",\"value\":\"1\"}]",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation -o jsonpath='{.spec.template.spec.containers[*].envFrom}'\")",
      "command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation-f819b557 -o jsonpath='{.spec.template.spec.containers[*].envFrom}'\")",
      "result": "",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -l io.kompose.service=mongodb-geo\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -l io.kompose.service=mongodb-geo\")",
      "result": "NAME                           READY   STATUS    RESTARTS   AGE\nmongodb-geo-5ff578bcb8-k5hd4   1/1     Running   0          27s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get service -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get service -n test-hotel-reservation-f819b557\")",
      "result": "NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                       AGE\nconsul                   ClusterIP   10.96.121.138   <none>        8300/TCP,8400/TCP,8500/TCP,8600/UDP                                           50s\nfrontend                 ClusterIP   10.96.155.90    <none>        5000/TCP                                                                      50s\ngeo                      ClusterIP   10.96.129.251   <none>        8083/TCP                                                                      50s\njaeger                   ClusterIP   10.96.138.87    <none>        14269/TCP,5778/TCP,14268/TCP,14267/TCP,16686/TCP,5775/UDP,6831/UDP,6832/UDP   50s\njaeger-out               NodePort    10.96.84.128    <none>        16686:31512/TCP                                                               50s\nmemcached-profile        ClusterIP   10.96.91.63     <none>        11211/TCP                                                                     50s\nmemcached-rate           ClusterIP   10.96.147.165   <none>        11211/TCP                                                                     50s\nmemcached-reserve        ClusterIP   10.96.175.194   <none>        11211/TCP                                                                     50s\nmongodb-geo              ClusterIP   10.96.86.217    <none>        27017/TCP                                                                     50s\nmongodb-profile          ClusterIP   10.96.2.190     <none>        27017/TCP                                                                     50s\nmongodb-rate             ClusterIP   10.96.211.242   <none>        27017/TCP                                                                     50s\nmongodb-recommendation   ClusterIP   10.96.103.58    <none>        27017/TCP                                                                     50s\nmongodb-reservation      ClusterIP   10.96.244.129   <none>        27017/TCP                                                                     50s\nmongodb-user             ClusterIP   10.96.246.125   <none>        27017/TCP                                                                     50s\nprofile                  ClusterIP   10.96.214.20    <none>        8081/TCP                                                                      50s\nrate                     ClusterIP   10.96.69.233    <none>        8084/TCP                                                                      50s\nrecommendation           ClusterIP   10.96.56.244    <none>        8085/TCP                                                                      50s\nreservation              ClusterIP   10.96.244.90    <none>        8087/TCP                                                                      50s\nsearch                   ClusterIP   10.96.213.167   <none>        8082/TCP                                                                      50s\nuser                     ClusterIP   10.96.105.29    <none>        8086/TCP                                                                      50s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get service mongodb-geo -n test-hotel-reservation -o yaml\")",
      "command": "exec_shell(\"kubectl get service mongodb-geo -n test-hotel-reservation-f819b557 -o yaml\")",
      "result": "apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    kompose.cmd: kompose convert\n    kompose.version: 1.22.0 (955b78124)\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{\"kompose.cmd\":\"kompose convert\",\"kompose.version\":\"1.22.0 (955b78124)\"},\"creationTimestamp\":null,\"labels\":{\"io.kompose.service\":\"mongodb-geo\"},\"name\":\"mongodb-geo\",\"namespace\":\"test-hotel-reservation-f819b557\"},\"spec\":{\"ports\":[{\"name\":\"mongodb-geo\",\"port\":27017,\"targetPort\":27017}],\"selector\":{\"io.kompose.service\":\"mongodb-geo\"}},\"status\":{\"loadBalancer\":{}}}\n  creationTimestamp: \"2025-12-24T10:17:19Z\"\n  labels:\n    io.kompose.service: mongodb-geo\n  name: mongodb-geo\n  namespace: test-hotel-reservation-f819b557\n  resourceVersion: \"73064\"\n  uid: 12989681-ff5f-4e59-b960-c387208fdbac\nspec:\n  clusterIP: 10.96.86.217\n  clusterIPs:\n  - 10.96.86.217\n  internalTrafficPolicy: Cluster\n  ipFamilies:\n  - IPv4\n  ipFamilyPolicy: SingleStack\n  ports:\n  - name: mongodb-geo\n    port: 27017\n    protocol: TCP\n    targetPort: 27017\n  selector:\n    io.kompose.service: mongodb-geo\n  sessionAffinity: None\n  type: ClusterIP\nstatus:\n  loadBalancer: {}\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get endpoints -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get endpoints -n test-hotel-reservation-f819b557\")",
      "result": "NAME                     ENDPOINTS                                                            AGE\nconsul                   10.244.1.183:8300,10.244.1.183:8400,10.244.1.183:53 + 1 more...      52s\nfrontend                 10.244.1.184:5000                                                    52s\ngeo                                                                                           52s\njaeger                   10.244.1.187:6832,10.244.1.187:14268,10.244.1.187:5775 + 5 more...   52s\njaeger-out               10.244.1.187:16686                                                   52s\nmemcached-profile        10.244.1.188:11211                                                   52s\nmemcached-rate           10.244.1.191:11211                                                   52s\nmemcached-reserve        10.244.1.195:11211                                                   52s\nmongodb-geo              10.244.1.209:27017                                                   52s\nmongodb-profile          10.244.1.200:27017                                                   52s\nmongodb-rate             10.244.1.202:27017                                                   52s\nmongodb-recommendation   10.244.1.205:27017                                                   52s\nmongodb-reservation      10.244.1.206:27017                                                   52s\nmongodb-user             10.244.1.207:27017                                                   52s\nprofile                  10.244.1.190:8081                                                    52s\nrate                     10.244.1.193:8084                                                    52s\nrecommendation           10.244.1.194:8085                                                    52s\nreservation              10.244.1.197:8087                                                    52s\nsearch                   10.244.1.198:8082                                                    52s\nuser                     10.244.1.199:8086                                                    52s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe service mongodb-geo -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl describe service mongodb-geo -n test-hotel-reservation-f819b557\")",
      "result": "Name:                     mongodb-geo\nNamespace:                test-hotel-reservation-f819b557\nLabels:                   io.kompose.service=mongodb-geo\nAnnotations:              kompose.cmd: kompose convert\n                          kompose.version: 1.22.0 (955b78124)\nSelector:                 io.kompose.service=mongodb-geo\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.96.86.217\nIPs:                      10.96.86.217\nPort:                     mongodb-geo  27017/TCP\nTargetPort:               27017/TCP\nEndpoints:                10.244.1.209:27017\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -o wide | grep mongodb\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -o wide | grep mongodb\")",
      "result": "mongodb-geo-5ff578bcb8-k5hd4              1/1     Running     0             31s   10.244.1.209   kind-worker   <none>           <none>\nmongodb-profile-758cb77f9f-fb9r6          1/1     Running     0             53s   10.244.1.200   kind-worker   <none>           <none>\nmongodb-rate-56cc8659c9-t765c             1/1     Running     0             53s   10.244.1.202   kind-worker   <none>           <none>\nmongodb-recommendation-55699465f7-f7d95   1/1     Running     0             52s   10.244.1.205   kind-worker   <none>           <none>\nmongodb-reservation-5994859869-4m59j      1/1     Running     0             52s   10.244.1.206   kind-worker   <none>           <none>\nmongodb-user-969c6c449-2cdt2              1/1     Running     0             51s   10.244.1.207   kind-worker   <none>           <none>\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe pod -n test-hotel-reservation -l io.kompose.service=mongodb-geo\")",
      "command": "exec_shell(\"kubectl describe pod -n test-hotel-reservation-f819b557 -l io.kompose.service=mongodb-geo\")",
      "result": "Name:             mongodb-geo-5ff578bcb8-k5hd4\nNamespace:        test-hotel-reservation-f819b557\nPriority:         0\nService Account:  default\nNode:             kind-worker/172.18.0.2\nStart Time:       Wed, 24 Dec 2025 18:17:41 +0800\nLabels:           io.kompose.service=mongodb-geo\n                  pod-template-hash=5ff578bcb8\nAnnotations:      kompose.cmd: kompose convert\n                  kompose.version: 1.22.0 (955b78124)\n                  sidecar.istio.io/statsInclusionPrefixes:\n                    cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\n                  sidecar.istio.io/statsInclusionRegexps: http.*\nStatus:           Running\nIP:               10.244.1.209\nIPs:\n  IP:           10.244.1.209\nControlled By:  ReplicaSet/mongodb-geo-5ff578bcb8\nContainers:\n  hotel-reserv-geo-mongo:\n    Container ID:  containerd://32d192aa8817655f81cde0aa4c0b2e191d7d2539277830c4386a7950cee18a65\n    Image:         mongo:4.4.6\n    Image ID:      docker.io/library/import-2025-12-24@sha256:69380384c9222401e0d450da3d6e85f74840b2421bb27369c18d62ee2c875f53\n    Port:          27017/TCP\n    Host Port:     0/TCP\n    Args:\n      --auth\n    State:          Running\n      Started:      Wed, 24 Dec 2025 18:17:42 +0800\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      cpu:  1\n    Requests:\n      cpu:        100m\n    Environment:  <none>\n    Mounts:\n      /data/db from geo (rw)\n      /docker-entrypoint-initdb.d from init-script (rw)\n      /scripts from failure-script (rw)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-dq2ld (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  geo:\n    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\n    ClaimName:  geo-pvc\n    ReadOnly:   false\n  init-script:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      mongo-geo-script\n    Optional:  false\n  failure-script:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      failure-admin-geo\n    Optional:  false\n  kube-api-access-dq2ld:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    Optional:                false\n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  32s   default-scheduler  Successfully assigned test-hotel-reservation-f819b557/mongodb-geo-5ff578bcb8-k5hd4 to kind-worker\n  Normal  Pulled     31s   kubelet            Container image \"mongo:4.4.6\" already present on machine\n  Normal  Created    31s   kubelet            Created container: hotel-reserv-geo-mongo\n  Normal  Started    31s   kubelet            Started container hotel-reserv-geo-mongo\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl logs -n test-hotel-reservation -l io.kompose.service=mongodb-geo --tail=50\")",
      "command": "exec_shell(\"kubectl logs -n test-hotel-reservation-f819b557 -l io.kompose.service=mongodb-geo --tail=50\")",
      "result": "{\"t\":{\"$date\":\"2025-12-24T10:17:42.816+00:00\"},\"s\":\"I\",  \"c\":\"CONTROL\",  \"id\":23285,   \"ctx\":\"main\",\"msg\":\"Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'\"}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.818+00:00\"},\"s\":\"W\",  \"c\":\"ASIO\",     \"id\":22601,   \"ctx\":\"main\",\"msg\":\"No TransportLayer configured during NetworkInterface startup\"}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.818+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":4648601, \"ctx\":\"main\",\"msg\":\"Implicit TCP FastOpen unavailable. If TCP FastOpen is required, set tcpFastOpenServer, tcpFastOpenClient, and tcpFastOpenQueueSize.\"}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.819+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":4615611, \"ctx\":\"initandlisten\",\"msg\":\"MongoDB starting\",\"attr\":{\"pid\":1,\"port\":27017,\"dbPath\":\"/data/db\",\"architecture\":\"64-bit\",\"host\":\"mongodb-geo-5ff578bcb8-k5hd4\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.819+00:00\"},\"s\":\"I\",  \"c\":\"CONTROL\",  \"id\":23403,   \"ctx\":\"initandlisten\",\"msg\":\"Build Info\",\"attr\":{\"buildInfo\":{\"version\":\"4.4.6\",\"gitVersion\":\"72e66213c2c3eab37d9358d5e78ad7f5c1d0d0d7\",\"openSSLVersion\":\"OpenSSL 1.1.1  11 Sep 2018\",\"modules\":[],\"allocator\":\"tcmalloc\",\"environment\":{\"distmod\":\"ubuntu1804\",\"distarch\":\"x86_64\",\"target_arch\":\"x86_64\"}}}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.819+00:00\"},\"s\":\"I\",  \"c\":\"CONTROL\",  \"id\":51765,   \"ctx\":\"initandlisten\",\"msg\":\"Operating System\",\"attr\":{\"os\":{\"name\":\"Ubuntu\",\"version\":\"18.04\"}}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.819+00:00\"},\"s\":\"I\",  \"c\":\"CONTROL\",  \"id\":21951,   \"ctx\":\"initandlisten\",\"msg\":\"Options set by command line\",\"attr\":{\"options\":{\"net\":{\"bindIp\":\"*\"},\"security\":{\"authorization\":\"enabled\"}}}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.874+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22270,   \"ctx\":\"initandlisten\",\"msg\":\"Storage engine to use detected by data files\",\"attr\":{\"dbpath\":\"/data/db\",\"storageEngine\":\"wiredTiger\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.874+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22297,   \"ctx\":\"initandlisten\",\"msg\":\"Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http://dochub.mongodb.org/core/prodnotes-filesystem\",\"tags\":[\"startupWarnings\"]}\n{\"t\":{\"$date\":\"2025-12-24T10:17:42.874+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22315,   \"ctx\":\"initandlisten\",\"msg\":\"Opening WiredTiger\",\"attr\":{\"config\":\"create,cache_size=15373M,session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress,compact_progress],\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.034+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:34523][1:0x7de52b0faac0], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 2 through 3\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.060+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:60143][1:0x7de52b0faac0], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 3 through 3\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.124+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:124611][1:0x7de52b0faac0], txn-recover: [WT_VERB_RECOVERY | WT_VERB_RECOVERY_PROGRESS] Main recovery loop: starting at 2/26880 to 3/256\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.174+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:174758][1:0x7de52b0faac0], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 2 through 3\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.208+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:208179][1:0x7de52b0faac0], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 3 through 3\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.225+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:225973][1:0x7de52b0faac0], txn-recover: [WT_VERB_RECOVERY | WT_VERB_RECOVERY_PROGRESS] Set global recovery timestamp: (0, 0)\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.226+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:226025][1:0x7de52b0faac0], txn-recover: [WT_VERB_RECOVERY | WT_VERB_RECOVERY_PROGRESS] Set global oldest timestamp: (0, 0)\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.227+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22430,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger message\",\"attr\":{\"message\":\"[1766571463:227633][1:0x7de52b0faac0], WT_SESSION.checkpoint: [WT_VERB_CHECKPOINT_PROGRESS] saving checkpoint snapshot min: 1, snapshot max: 1 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0)\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.233+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":4795906, \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger opened\",\"attr\":{\"durationMillis\":359}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.233+00:00\"},\"s\":\"I\",  \"c\":\"RECOVERY\", \"id\":23987,   \"ctx\":\"initandlisten\",\"msg\":\"WiredTiger recoveryTimestamp\",\"attr\":{\"recoveryTimestamp\":{\"$timestamp\":{\"t\":0,\"i\":0}}}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.233+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":4366408, \"ctx\":\"initandlisten\",\"msg\":\"No table logging settings modifications are required for existing WiredTiger tables\",\"attr\":{\"loggingEnabled\":true}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.234+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":22262,   \"ctx\":\"initandlisten\",\"msg\":\"Timestamp monitor starting\"}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.238+00:00\"},\"s\":\"I\",  \"c\":\"STORAGE\",  \"id\":20536,   \"ctx\":\"initandlisten\",\"msg\":\"Flow Control is enabled on this deployment\"}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.240+00:00\"},\"s\":\"I\",  \"c\":\"FTDC\",     \"id\":20625,   \"ctx\":\"initandlisten\",\"msg\":\"Initializing full-time diagnostic data capture\",\"attr\":{\"dataDirectory\":\"/data/db/diagnostic.data\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.241+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":23015,   \"ctx\":\"listener\",\"msg\":\"Listening on\",\"attr\":{\"address\":\"/tmp/mongodb-27017.sock\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.241+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":23015,   \"ctx\":\"listener\",\"msg\":\"Listening on\",\"attr\":{\"address\":\"0.0.0.0\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:43.241+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":23016,   \"ctx\":\"listener\",\"msg\":\"Waiting for connections\",\"attr\":{\"port\":27017,\"ssl\":\"off\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:48.159+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":22943,   \"ctx\":\"listener\",\"msg\":\"Connection accepted\",\"attr\":{\"remote\":\"10.244.1.208:48210\",\"connectionId\":1,\"connectionCount\":1}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:48.161+00:00\"},\"s\":\"I\",  \"c\":\"ACCESS\",   \"id\":20249,   \"ctx\":\"conn1\",\"msg\":\"Authentication failed\",\"attr\":{\"mechanism\":\"SCRAM-SHA-1\",\"speculative\":false,\"principalName\":\"admin\",\"authenticationDatabase\":\"admin\",\"remote\":\"10.244.1.208:48210\",\"extraInfo\":{},\"error\":\"UserNotFound: Could not find user \\\"admin\\\" for db \\\"admin\\\"\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:17:48.162+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":22944,   \"ctx\":\"conn1\",\"msg\":\"Connection ended\",\"attr\":{\"remote\":\"10.244.1.208:48210\",\"connectionId\":1,\"connectionCount\":0}}\n{\"t\":{\"$date\":\"2025-12-24T10:18:00.742+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":22943,   \"ctx\":\"listener\",\"msg\":\"Connection accepted\",\"attr\":{\"remote\":\"10.244.1.208:48810\",\"connectionId\":2,\"connectionCount\":1}}\n{\"t\":{\"$date\":\"2025-12-24T10:18:00.743+00:00\"},\"s\":\"I\",  \"c\":\"ACCESS\",   \"id\":20249,   \"ctx\":\"conn2\",\"msg\":\"Authentication failed\",\"attr\":{\"mechanism\":\"SCRAM-SHA-1\",\"speculative\":false,\"principalName\":\"admin\",\"authenticationDatabase\":\"admin\",\"remote\":\"10.244.1.208:48810\",\"extraInfo\":{},\"error\":\"UserNotFound: Could not find user \\\"admin\\\" for db \\\"admin\\\"\"}}\n{\"t\":{\"$date\":\"2025-12-24T10:18:00.743+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":22944,   \"ctx\":\"conn2\",\"msg\":\"Connection ended\",\"attr\":{\"remote\":\"10.244.1.208:48810\",\"connectionId\":2,\"connectionCount\":0}}\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl exec -n test-hotel-reservation geo-84fbc958c7-zcfdf -- env\")",
      "command": "exec_shell(\"kubectl exec -n test-hotel-reservation-f819b557 geo-84fbc958c7-zcfdf -- env\")",
      "result": "Error from server (NotFound): pods \"geo-84fbc958c7-zcfdf\" not found\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment -n test-hotel-reservation -o wide\")",
      "command": "exec_shell(\"kubectl get deployment -n test-hotel-reservation-f819b557 -o wide\")",
      "result": "NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS                          IMAGES                                SELECTOR\nconsul                   1/1     1            1           56s   consul                              hashicorp/consul:latest               io.kompose.service=consul\nfrontend                 1/1     1            1           56s   hotel-reserv-frontend               yinfangchen/hotelreservation:latest   io.kompose.service=frontend\ngeo                      0/1     1            0           56s   hotel-reserv-geo                    yinfangchen/hotelreservation:latest   io.kompose.service=geo\njaeger                   1/1     1            1           56s   hotel-reserv-jaeger                 jaegertracing/all-in-one:1.57         io.kompose.service=jaeger\nmemcached-profile        1/1     1            1           56s   hotel-reserv-profile-mmc            memcached:1.6.7                       io.kompose.service=memcached-profile\nmemcached-rate           1/1     1            1           56s   hotel-reserv-rate-mmc               memcached:1.6.7                       io.kompose.service=memcached-rate\nmemcached-reserve        1/1     1            1           56s   hotel-reserv-reservation-mmc        memcached:1.6.7                       io.kompose.service=memcached-reserve\nmongodb-geo              1/1     1            1           56s   hotel-reserv-geo-mongo              mongo:4.4.6                           io.kompose.service=mongodb-geo\nmongodb-profile          1/1     1            1           56s   hotel-reserv-profile-mongo          mongo:4.4.6                           io.kompose.service=mongodb-profile\nmongodb-rate             1/1     1            1           56s   hotel-reserv-rate-mongo             mongo:4.4.6                           io.kompose.service=mongodb-rate\nmongodb-recommendation   1/1     1            1           56s   hotel-reserv-recommendation-mongo   mongo:4.4.6                           io.kompose.service=mongodb-recommendation\nmongodb-reservation      1/1     1            1           56s   hotel-reserv-reservation-mongo      mongo:4.4.6                           io.kompose.service=mongodb-reservation\nmongodb-user             1/1     1            1           56s   hotel-reserv-user-mongo             mongo:4.4.6                           io.kompose.service=mongodb-user\nprofile                  1/1     1            1           56s   hotel-reserv-profile                yinfangchen/hotelreservation:latest   io.kompose.service=profile\nrate                     1/1     1            1           56s   hotel-reserv-rate                   yinfangchen/hotelreservation:latest   io.kompose.service=rate\nrecommendation           1/1     1            1           56s   hotel-reserv-recommendation         yinfangchen/hotelreservation:latest   io.kompose.service=recommendation\nreservation              1/1     1            1           56s   hotel-reserv-reservation            yinfangchen/hotelreservation:latest   io.kompose.service=reservation\nsearch                   1/1     1            1           56s   hotel-reserv-search                 yinfangchen/hotelreservation:latest   io.kompose.service=search\nuser                     1/1     1            1           56s   hotel-reserv-user                   yinfangchen/hotelreservation:latest   io.kompose.service=user\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get statefulset -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get statefulset -n test-hotel-reservation-f819b557\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pv\")",
      "command": "exec_shell(\"kubectl get pv\")",
      "result": "NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                                STORAGECLASS       VOLUMEATTRIBUTESCLASS   REASON   AGE\npvc-1475f7a5-03d6-4bc5-aa5c-a7c23eb254a4   1Gi        RWO            Delete           Bound    test-hotel-reservation-f819b557/recommendation-pvc   openebs-hostpath   <unset>                          47s\npvc-38d48591-b944-4d91-aa2c-bcf630ac60f8   8Gi        RWO            Delete           Bound    observe/prometheus-server                            openebs-hostpath   <unset>                          114m\npvc-96b3bdbd-08e8-450b-8194-f39f67e80d1c   1Gi        RWO            Delete           Bound    test-hotel-reservation-f819b557/profile-pvc          openebs-hostpath   <unset>                          51s\npvc-abab6a4f-d4f6-4228-a30e-31ab70a4d21a   1Gi        RWO            Delete           Bound    test-hotel-reservation-f819b557/geo-pvc              openebs-hostpath   <unset>                          48s\npvc-ca82b26d-7f8d-4f31-82ef-54a1543e1473   1Gi        RWO            Delete           Bound    test-hotel-reservation-f819b557/rate-pvc             openebs-hostpath   <unset>                          49s\npvc-d7b1e73b-25d9-48f6-a3e3-fd2e6eba7776   1Gi        RWO            Delete           Bound    test-hotel-reservation-f819b557/user-pvc             openebs-hostpath   <unset>                          42s\npvc-fbc13203-ee84-41fa-a538-a8b754d43a43   1Gi        RWO            Delete           Bound    test-hotel-reservation-f819b557/reservation-pvc      openebs-hostpath   <unset>                          45s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pvc -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get pvc -n test-hotel-reservation-f819b557\")",
      "result": "NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       VOLUMEATTRIBUTESCLASS   AGE\ngeo-pvc              Bound    pvc-abab6a4f-d4f6-4228-a30e-31ab70a4d21a   1Gi        RWO            openebs-hostpath   <unset>                 58s\nprofile-pvc          Bound    pvc-96b3bdbd-08e8-450b-8194-f39f67e80d1c   1Gi        RWO            openebs-hostpath   <unset>                 58s\nrate-pvc             Bound    pvc-ca82b26d-7f8d-4f31-82ef-54a1543e1473   1Gi        RWO            openebs-hostpath   <unset>                 58s\nrecommendation-pvc   Bound    pvc-1475f7a5-03d6-4bc5-aa5c-a7c23eb254a4   1Gi        RWO            openebs-hostpath   <unset>                 58s\nreservation-pvc      Bound    pvc-fbc13203-ee84-41fa-a538-a8b754d43a43   1Gi        RWO            openebs-hostpath   <unset>                 58s\nuser-pvc             Bound    pvc-d7b1e73b-25d9-48f6-a3e3-fd2e6eba7776   1Gi        RWO            openebs-hostpath   <unset>                 58s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe pvc -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl describe pvc -n test-hotel-reservation-f819b557\")",
      "result": "Name:          geo-pvc\nNamespace:     test-hotel-reservation-f819b557\nStorageClass:  openebs-hostpath\nStatus:        Bound\nVolume:        pvc-abab6a4f-d4f6-4228-a30e-31ab70a4d21a\nLabels:        <none>\nAnnotations:   pv.kubernetes.io/bind-completed: yes\n               pv.kubernetes.io/bound-by-controller: yes\n               volume.beta.kubernetes.io/storage-provisioner: openebs.io/local\n               volume.kubernetes.io/selected-node: kind-worker\n               volume.kubernetes.io/storage-provisioner: openebs.io/local\nFinalizers:    [kubernetes.io/pvc-protection]\nCapacity:      1Gi\nAccess Modes:  RWO\nVolumeMode:    Filesystem\nUsed By:       mongodb-geo-5ff578bcb8-k5hd4\nEvents:\n  Type    Reason                 Age                From                                                                                                Message\n  ----    ------                 ----               ----                                                                                                -------\n  Normal  WaitForFirstConsumer   59s                persistentvolume-controller                                                                         waiting for first consumer to be created before binding\n  Normal  Provisioning           59s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/geo-pvc\"\n  Normal  ExternalProvisioning   52s (x2 over 59s)  persistentvolume-controller                                                                         Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n  Normal  ProvisioningSucceeded  49s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  Successfully provisioned volume pvc-abab6a4f-d4f6-4228-a30e-31ab70a4d21a\n\n\nName:          profile-pvc\nNamespace:     test-hotel-reservation-f819b557\nStorageClass:  openebs-hostpath\nStatus:        Bound\nVolume:        pvc-96b3bdbd-08e8-450b-8194-f39f67e80d1c\nLabels:        <none>\nAnnotations:   pv.kubernetes.io/bind-completed: yes\n               pv.kubernetes.io/bound-by-controller: yes\n               volume.beta.kubernetes.io/storage-provisioner: openebs.io/local\n               volume.kubernetes.io/selected-node: kind-worker\n               volume.kubernetes.io/storage-provisioner: openebs.io/local\nFinalizers:    [kubernetes.io/pvc-protection]\nCapacity:      1Gi\nAccess Modes:  RWO\nVolumeMode:    Filesystem\nUsed By:       mongodb-profile-758cb77f9f-fb9r6\nEvents:\n  Type    Reason                 Age                From                                                                                                Message\n  ----    ------                 ----               ----                                                                                                -------\n  Normal  WaitForFirstConsumer   59s                persistentvolume-controller                                                                         waiting for first consumer to be created before binding\n  Normal  ExternalProvisioning   59s (x2 over 59s)  persistentvolume-controller                                                                         Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n  Normal  Provisioning           59s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/profile-pvc\"\n  Normal  ProvisioningSucceeded  52s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  Successfully provisioned volume pvc-96b3bdbd-08e8-450b-8194-f39f67e80d1c\n\n\nName:          rate-pvc\nNamespace:     test-hotel-reservation-f819b557\nStorageClass:  openebs-hostpath\nStatus:        Bound\nVolume:        pvc-ca82b26d-7f8d-4f31-82ef-54a1543e1473\nLabels:        <none>\nAnnotations:   pv.kubernetes.io/bind-completed: yes\n               pv.kubernetes.io/bound-by-controller: yes\n               volume.beta.kubernetes.io/storage-provisioner: openebs.io/local\n               volume.kubernetes.io/selected-node: kind-worker\n               volume.kubernetes.io/storage-provisioner: openebs.io/local\nFinalizers:    [kubernetes.io/pvc-protection]\nCapacity:      1Gi\nAccess Modes:  RWO\nVolumeMode:    Filesystem\nUsed By:       mongodb-rate-56cc8659c9-t765c\nEvents:\n  Type    Reason                 Age                From                                                                                                Message\n  ----    ------                 ----               ----                                                                                                -------\n  Normal  WaitForFirstConsumer   59s                persistentvolume-controller                                                                         waiting for first consumer to be created before binding\n  Normal  Provisioning           59s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/rate-pvc\"\n  Normal  ExternalProvisioning   52s (x2 over 59s)  persistentvolume-controller                                                                         Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n  Normal  ProvisioningSucceeded  50s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  Successfully provisioned volume pvc-ca82b26d-7f8d-4f31-82ef-54a1543e1473\n\n\nName:          recommendation-pvc\nNamespace:     test-hotel-reservation-f819b557\nStorageClass:  openebs-hostpath\nStatus:        Bound\nVolume:        pvc-1475f7a5-03d6-4bc5-aa5c-a7c23eb254a4\nLabels:        <none>\nAnnotations:   pv.kubernetes.io/bind-completed: yes\n               pv.kubernetes.io/bound-by-controller: yes\n               volume.beta.kubernetes.io/storage-provisioner: openebs.io/local\n               volume.kubernetes.io/selected-node: kind-worker\n               volume.kubernetes.io/storage-provisioner: openebs.io/local\nFinalizers:    [kubernetes.io/pvc-protection]\nCapacity:      1Gi\nAccess Modes:  RWO\nVolumeMode:    Filesystem\nUsed By:       mongodb-recommendation-55699465f7-f7d95\nEvents:\n  Type    Reason                 Age                From                                                                                                Message\n  ----    ------                 ----               ----                                                                                                -------\n  Normal  WaitForFirstConsumer   59s                persistentvolume-controller                                                                         waiting for first consumer to be created before binding\n  Normal  Provisioning           58s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/recommendation-pvc\"\n  Normal  ExternalProvisioning   52s (x2 over 58s)  persistentvolume-controller                                                                         Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n  Normal  ProvisioningSucceeded  48s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  Successfully provisioned volume pvc-1475f7a5-03d6-4bc5-aa5c-a7c23eb254a4\n\n\nName:          reservation-pvc\nNamespace:     test-hotel-reservation-f819b557\nStorageClass:  openebs-hostpath\nStatus:        Bound\nVolume:        pvc-fbc13203-ee84-41fa-a538-a8b754d43a43\nLabels:        <none>\nAnnotations:   pv.kubernetes.io/bind-completed: yes\n               pv.kubernetes.io/bound-by-controller: yes\n               volume.beta.kubernetes.io/storage-provisioner: openebs.io/local\n               volume.kubernetes.io/selected-node: kind-worker\n               volume.kubernetes.io/storage-provisioner: openebs.io/local\nFinalizers:    [kubernetes.io/pvc-protection]\nCapacity:      1Gi\nAccess Modes:  RWO\nVolumeMode:    Filesystem\nUsed By:       mongodb-reservation-5994859869-4m59j\nEvents:\n  Type    Reason                 Age                From                                                                                                Message\n  ----    ------                 ----               ----                                                                                                -------\n  Normal  WaitForFirstConsumer   59s                persistentvolume-controller                                                                         waiting for first consumer to be created before binding\n  Normal  ExternalProvisioning   52s (x3 over 58s)  persistentvolume-controller                                                                         Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n  Normal  Provisioning           51s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/reservation-pvc\"\n  Normal  ProvisioningSucceeded  46s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  Successfully provisioned volume pvc-fbc13203-ee84-41fa-a538-a8b754d43a43\n\n\nName:          user-pvc\nNamespace:     test-hotel-reservation-f819b557\nStorageClass:  openebs-hostpath\nStatus:        Bound\nVolume:        pvc-d7b1e73b-25d9-48f6-a3e3-fd2e6eba7776\nLabels:        <none>\nAnnotations:   pv.kubernetes.io/bind-completed: yes\n               pv.kubernetes.io/bound-by-controller: yes\n               volume.beta.kubernetes.io/storage-provisioner: openebs.io/local\n               volume.kubernetes.io/selected-node: kind-worker\n               volume.kubernetes.io/storage-provisioner: openebs.io/local\nFinalizers:    [kubernetes.io/pvc-protection]\nCapacity:      1Gi\nAccess Modes:  RWO\nVolumeMode:    Filesystem\nUsed By:       mongodb-user-969c6c449-2cdt2\nEvents:\n  Type    Reason                 Age                From                                                                                                Message\n  ----    ------                 ----               ----                                                                                                -------\n  Normal  WaitForFirstConsumer   59s                persistentvolume-controller                                                                         waiting for first consumer to be created before binding\n  Normal  ExternalProvisioning   52s (x3 over 57s)  persistentvolume-controller                                                                         Waiting for a volume to be created either by the external provisioner 'openebs.io/local' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.\n  Normal  Provisioning           49s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  External provisioner is provisioning volume for claim \"test-hotel-reservation-f819b557/user-pvc\"\n  Normal  ProvisioningSucceeded  43s                openebs.io/local_openebs-localpv-provisioner-65dd55b8dc-9kgf4_9e2aed7c-414f-4d66-8d37-3c5b8e214503  Successfully provisioned volume pvc-d7b1e73b-25d9-48f6-a3e3-fd2e6eba7776\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get storageclass\")",
      "command": "exec_shell(\"kubectl get storageclass\")",
      "result": "NAME                         PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nopenebs-device               openebs.io/local        Delete          WaitForFirstConsumer   false                  114m\nopenebs-hostpath (default)   openebs.io/local        Delete          WaitForFirstConsumer   false                  114m\nstandard (default)           rancher.io/local-path   Delete          WaitForFirstConsumer   false                  118m\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get networkpolicy -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get networkpolicy -n test-hotel-reservation-f819b557\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe networkpolicy -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl describe networkpolicy -n test-hotel-reservation-f819b557\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get ingress -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get ingress -n test-hotel-reservation-f819b557\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl top pods -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl top pods -n test-hotel-reservation-f819b557\")",
      "result": "error: Metrics API not available\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.status.containerStatuses[*].restartCount}{\\\"\\n\\\"}{end}'\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.status.containerStatuses[*].restartCount}{\\\"\\n\\\"}{end}'\")",
      "result": "consul-78c8d79bb-qtch4\t0\nfrontend-7fc7ddc9db-tp7km\t0\ngeo-84fbc958c7-v9jpp\t2\njaeger-67445b6dd6-mz9dd\t0\nmemcached-profile-668dcd6dbb-xk8vx\t0\nmemcached-rate-5b666ddfcb-s4s9p\t0\nmemcached-reserve-5bf87f5d54-gbdxj\t0\nmongodb-geo-5ff578bcb8-k5hd4\t0\nmongodb-profile-758cb77f9f-fb9r6\t0\nmongodb-rate-56cc8659c9-t765c\t0\nmongodb-recommendation-55699465f7-f7d95\t0\nmongodb-reservation-5994859869-4m59j\t0\nmongodb-user-969c6c449-2cdt2\t0\nprofile-8b6dd7c6c-57q4n\t1\nrate-7bdc978679-zkffp\t1\nrecommendation-6879fb56bf-hnbz5\t1\nreservation-78c9f7976b-5rfxh\t0\nsearch-5c64c8f5bc-8gzg7\t0\nuser-66d5d6f874-vtqcb\t1\nwrk2-job-f819b557-k4w7n\t0\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get events -n test-hotel-reservation --field-selector type=Warning\")",
      "command": "exec_shell(\"kubectl get events -n test-hotel-reservation-f819b557 --field-selector type=Warning\")",
      "result": "LAST SEEN   TYPE      REASON    OBJECT                     MESSAGE\n8s          Warning   BackOff   pod/geo-84fbc958c7-v9jpp   Back-off restarting failed container hotel-reserv-geo in pod geo-84fbc958c7-v9jpp_test-hotel-reservation-f819b557(3a6acbd4-282e-4209-865e-b59fcdd95270)\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get events -n test-hotel-reservation --field-selector reason=Failed\")",
      "command": "exec_shell(\"kubectl get events -n test-hotel-reservation-f819b557 --field-selector reason=Failed\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.status.phase}{\\\"\\t\\\"}{.status.conditions[?(@.type==\\\"Ready\\\")].status}{\\\"\\n\\\"}{end}'\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.status.phase}{\\\"\\t\\\"}{.status.conditions[?(@.type==\\\"Ready\\\")].status}{\\\"\\n\\\"}{end}'\")",
      "result": "consul-78c8d79bb-qtch4\tRunning\tTrue\nfrontend-7fc7ddc9db-tp7km\tRunning\tTrue\ngeo-84fbc958c7-v9jpp\tRunning\tFalse\njaeger-67445b6dd6-mz9dd\tRunning\tTrue\nmemcached-profile-668dcd6dbb-xk8vx\tRunning\tTrue\nmemcached-rate-5b666ddfcb-s4s9p\tRunning\tTrue\nmemcached-reserve-5bf87f5d54-gbdxj\tRunning\tTrue\nmongodb-geo-5ff578bcb8-k5hd4\tRunning\tTrue\nmongodb-profile-758cb77f9f-fb9r6\tRunning\tTrue\nmongodb-rate-56cc8659c9-t765c\tRunning\tTrue\nmongodb-recommendation-55699465f7-f7d95\tRunning\tTrue\nmongodb-reservation-5994859869-4m59j\tRunning\tTrue\nmongodb-user-969c6c449-2cdt2\tRunning\tTrue\nprofile-8b6dd7c6c-57q4n\tRunning\tTrue\nrate-7bdc978679-zkffp\tRunning\tTrue\nrecommendation-6879fb56bf-hnbz5\tRunning\tTrue\nreservation-78c9f7976b-5rfxh\tRunning\tTrue\nsearch-5c64c8f5bc-8gzg7\tRunning\tTrue\nuser-66d5d6f874-vtqcb\tRunning\tTrue\nwrk2-job-f819b557-k4w7n\tSucceeded\tFalse\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation -o jsonpath='{.spec.template.spec.volumes}'\")",
      "command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation-f819b557 -o jsonpath='{.spec.template.spec.volumes}'\")",
      "result": "",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation -o jsonpath='{.spec.template.spec.containers[*].volumeMounts}'\")",
      "command": "exec_shell(\"kubectl get deployment geo -n test-hotel-reservation-f819b557 -o jsonpath='{.spec.template.spec.containers[*].volumeMounts}'\")",
      "result": "",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -l io.kompose.service=frontend -o wide\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -l io.kompose.service=frontend -o wide\")",
      "result": "NAME                        READY   STATUS    RESTARTS   AGE   IP             NODE          NOMINATED NODE   READINESS GATES\nfrontend-7fc7ddc9db-tp7km   1/1     Running   0          67s   10.244.1.184   kind-worker   <none>           <none>\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl logs -n test-hotel-reservation -l io.kompose.service=frontend --tail=50 | grep -i geo\")",
      "command": "exec_shell(\"kubectl logs -n test-hotel-reservation-f819b557 -l io.kompose.service=frontend --tail=50 | grep -i geo\")",
      "result": "",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get service geo -n test-hotel-reservation -o yaml\")",
      "command": "exec_shell(\"kubectl get service geo -n test-hotel-reservation-f819b557 -o yaml\")",
      "result": "apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    kompose.cmd: kompose convert\n    kompose.version: 1.22.0 (955b78124)\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{\"kompose.cmd\":\"kompose convert\",\"kompose.version\":\"1.22.0 (955b78124)\"},\"creationTimestamp\":null,\"labels\":{\"io.kompose.service\":\"geo\"},\"name\":\"geo\",\"namespace\":\"test-hotel-reservation-f819b557\"},\"spec\":{\"ports\":[{\"name\":\"8083\",\"port\":8083,\"targetPort\":8083}],\"selector\":{\"io.kompose.service\":\"geo\"}},\"status\":{\"loadBalancer\":{}}}\n  creationTimestamp: \"2025-12-24T10:17:19Z\"\n  labels:\n    io.kompose.service: geo\n  name: geo\n  namespace: test-hotel-reservation-f819b557\n  resourceVersion: \"73055\"\n  uid: 256a7464-08f2-4cd2-a082-e33143d3c9e6\nspec:\n  clusterIP: 10.96.129.251\n  clusterIPs:\n  - 10.96.129.251\n  internalTrafficPolicy: Cluster\n  ipFamilies:\n  - IPv4\n  ipFamilyPolicy: SingleStack\n  ports:\n  - name: \"8083\"\n    port: 8083\n    protocol: TCP\n    targetPort: 8083\n  selector:\n    io.kompose.service: geo\n  sessionAffinity: None\n  type: ClusterIP\nstatus:\n  loadBalancer: {}\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get endpoints geo -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl get endpoints geo -n test-hotel-reservation-f819b557\")",
      "result": "NAME   ENDPOINTS   AGE\ngeo                70s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe service geo -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl describe service geo -n test-hotel-reservation-f819b557\")",
      "result": "Name:                     geo\nNamespace:                test-hotel-reservation-f819b557\nLabels:                   io.kompose.service=geo\nAnnotations:              kompose.cmd: kompose convert\n                          kompose.version: 1.22.0 (955b78124)\nSelector:                 io.kompose.service=geo\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.96.129.251\nIPs:                      10.96.129.251\nPort:                     8083  8083/TCP\nTargetPort:               8083/TCP\nEndpoints:                \nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.spec.containers[*].image}{\\\"\\n\\\"}{end}'\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.spec.containers[*].image}{\\\"\\n\\\"}{end}'\")",
      "result": "consul-78c8d79bb-qtch4\thashicorp/consul:latest\nfrontend-7fc7ddc9db-tp7km\tyinfangchen/hotelreservation:latest\ngeo-84fbc958c7-v9jpp\tyinfangchen/hotelreservation:latest\njaeger-67445b6dd6-mz9dd\tjaegertracing/all-in-one:1.57\nmemcached-profile-668dcd6dbb-xk8vx\tmemcached:1.6.7\nmemcached-rate-5b666ddfcb-s4s9p\tmemcached:1.6.7\nmemcached-reserve-5bf87f5d54-gbdxj\tmemcached:1.6.7\nmongodb-geo-5ff578bcb8-k5hd4\tmongo:4.4.6\nmongodb-profile-758cb77f9f-fb9r6\tmongo:4.4.6\nmongodb-rate-56cc8659c9-t765c\tmongo:4.4.6\nmongodb-recommendation-55699465f7-f7d95\tmongo:4.4.6\nmongodb-reservation-5994859869-4m59j\tmongo:4.4.6\nmongodb-user-969c6c449-2cdt2\tmongo:4.4.6\nprofile-8b6dd7c6c-57q4n\tyinfangchen/hotelreservation:latest\nrate-7bdc978679-zkffp\tyinfangchen/hotelreservation:latest\nrecommendation-6879fb56bf-hnbz5\tyinfangchen/hotelreservation:latest\nreservation-78c9f7976b-5rfxh\tyinfangchen/hotelreservation:latest\nsearch-5c64c8f5bc-8gzg7\tyinfangchen/hotelreservation:latest\nuser-66d5d6f874-vtqcb\tyinfangchen/hotelreservation:latest\nwrk2-job-f819b557-k4w7n\tdeathstarbench/wrk2-client:latest\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get deployment -n test-hotel-reservation -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.spec.replicas}{\\\"\\t\\\"}{.status.availableReplicas}{\\\"\\n\\\"}{end}'\")",
      "command": "exec_shell(\"kubectl get deployment -n test-hotel-reservation-f819b557 -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.spec.replicas}{\\\"\\t\\\"}{.status.availableReplicas}{\\\"\\n\\\"}{end}'\")",
      "result": "consul\t1\t1\nfrontend\t1\t1\ngeo\t1\t\njaeger\t1\t1\nmemcached-profile\t1\t1\nmemcached-rate\t1\t1\nmemcached-reserve\t1\t1\nmongodb-geo\t1\t1\nmongodb-profile\t1\t1\nmongodb-rate\t1\t1\nmongodb-recommendation\t1\t1\nmongodb-reservation\t1\t1\nmongodb-user\t1\t1\nprofile\t1\t1\nrate\t1\t1\nrecommendation\t1\t1\nreservation\t1\t1\nsearch\t1\t1\nuser\t1\t1\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods geo-84fbc958c7-zcfdf -n test-hotel-reservation -o jsonpath='{.status.containerStatuses[*].state}'\")",
      "command": "exec_shell(\"kubectl get pods geo-84fbc958c7-zcfdf -n test-hotel-reservation-f819b557 -o jsonpath='{.status.containerStatuses[*].state}'\")",
      "result": "Error from server (NotFound): pods \"geo-84fbc958c7-zcfdf\" not found\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods geo-84fbc958c7-zcfdf -n test-hotel-reservation -o jsonpath='{.status.containerStatuses[*].lastState}'\")",
      "command": "exec_shell(\"kubectl get pods geo-84fbc958c7-zcfdf -n test-hotel-reservation-f819b557 -o jsonpath='{.status.containerStatuses[*].lastState}'\")",
      "result": "Error from server (NotFound): pods \"geo-84fbc958c7-zcfdf\" not found\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl describe node kind-worker\")",
      "command": "exec_shell(\"kubectl describe node kind-worker\")",
      "result": "Name:               kind-worker\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=kind-worker\n                    kubernetes.io/os=linux\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 24 Dec 2025 16:20:25 +0800\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  kind-worker\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 24 Dec 2025 18:18:30 +0800\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 24 Dec 2025 18:17:47 +0800   Wed, 24 Dec 2025 16:20:25 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 24 Dec 2025 18:17:47 +0800   Wed, 24 Dec 2025 16:20:25 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 24 Dec 2025 18:17:47 +0800   Wed, 24 Dec 2025 16:20:25 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 24 Dec 2025 18:17:47 +0800   Wed, 24 Dec 2025 16:20:38 +0800   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.18.0.2\n  Hostname:    kind-worker\nCapacity:\n  cpu:                24\n  ephemeral-storage:  1055762868Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             32532612Ki\n  pods:               110\nAllocatable:\n  cpu:                24\n  ephemeral-storage:  1055762868Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             32532612Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      a95f78babe7245b6b45c87986e0fb87f\n  System UUID:                     a95f78babe7245b6b45c87986e0fb87f\n  Boot ID:                         d1393028-3d99-4e5e-bc49-1199a48d63a4\n  Kernel Version:                  6.6.87.2-microsoft-standard-WSL2\n  OS Image:                        Debian GNU/Linux 12 (bookworm)\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.7.24\n  Kubelet Version:                 v1.32.0\n  Kube-Proxy Version:              v1.32.0\nPodCIDR:                           10.244.1.0/24\nPodCIDRs:                          10.244.1.0/24\nProviderID:                        kind://docker/kind/kind-worker\nNon-terminated Pods:               (37 in total)\n  Namespace                        Name                                                        CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                        ------------  ----------  ---------------  -------------  ---\n  chaos-mesh                       chaos-controller-manager-867799c5c-6qsmr                    25m (0%)      0 (0%)      256Mi (0%)       0 (0%)         43m\n  chaos-mesh                       chaos-controller-manager-867799c5c-89nln                    25m (0%)      0 (0%)      256Mi (0%)       0 (0%)         43m\n  chaos-mesh                       chaos-controller-manager-867799c5c-sgf4r                    25m (0%)      0 (0%)      256Mi (0%)       0 (0%)         43m\n  chaos-mesh                       chaos-daemon-268vv                                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         43m\n  chaos-mesh                       chaos-dashboard-6d89d47b7f-kxjhk                            25m (0%)      0 (0%)      256Mi (0%)       0 (0%)         43m\n  chaos-mesh                       chaos-dns-server-c5b549bdf-782g4                            100m (0%)     0 (0%)      70Mi (0%)        0 (0%)         43m\n  kube-system                      kindnet-4htl2                                               100m (0%)     100m (0%)   50Mi (0%)        50Mi (0%)      118m\n  kube-system                      kube-proxy-vwnmz                                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         118m\n  observe                          prometheus-kube-state-metrics-779b776cfb-2875l              0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  observe                          prometheus-prometheus-blackbox-exporter-7c6b445bb8-wvvh7    0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  observe                          prometheus-prometheus-node-exporter-rssv5                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  observe                          prometheus-prometheus-pushgateway-5464f67477-hmt99          0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  observe                          prometheus-server-56896fcb78-xb87d                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  openebs                          openebs-localpv-provisioner-65dd55b8dc-9kgf4                0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  openebs                          openebs-ndm-cluster-exporter-848db89c6-6mx5b                0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  openebs                          openebs-ndm-node-exporter-mv5js                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  openebs                          openebs-ndm-operator-5849bb84b8-m9ftp                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  openebs                          openebs-ndm-xkpcv                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         114m\n  test-hotel-reservation-f819b557  consul-78c8d79bb-qtch4                                      100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  frontend-7fc7ddc9db-tp7km                                   100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  geo-84fbc958c7-v9jpp                                        100m (0%)     1 (4%)      0 (0%)           0 (0%)         54s\n  test-hotel-reservation-f819b557  jaeger-67445b6dd6-mz9dd                                     100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  memcached-profile-668dcd6dbb-xk8vx                          100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  memcached-rate-5b666ddfcb-s4s9p                             100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  memcached-reserve-5bf87f5d54-gbdxj                          100m (0%)     1 (4%)      0 (0%)           0 (0%)         74s\n  test-hotel-reservation-f819b557  mongodb-geo-5ff578bcb8-k5hd4                                100m (0%)     1 (4%)      0 (0%)           0 (0%)         53s\n  test-hotel-reservation-f819b557  mongodb-profile-758cb77f9f-fb9r6                            100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  mongodb-rate-56cc8659c9-t765c                               100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  mongodb-recommendation-55699465f7-f7d95                     100m (0%)     1 (4%)      0 (0%)           0 (0%)         74s\n  test-hotel-reservation-f819b557  mongodb-reservation-5994859869-4m59j                        100m (0%)     1 (4%)      0 (0%)           0 (0%)         74s\n  test-hotel-reservation-f819b557  mongodb-user-969c6c449-2cdt2                                100m (0%)     1 (4%)      0 (0%)           0 (0%)         73s\n  test-hotel-reservation-f819b557  profile-8b6dd7c6c-57q4n                                     100m (0%)     1 (4%)      0 (0%)           0 (0%)         75s\n  test-hotel-reservation-f819b557  rate-7bdc978679-zkffp                                       100m (0%)     1 (4%)      0 (0%)           0 (0%)         74s\n  test-hotel-reservation-f819b557  recommendation-6879fb56bf-hnbz5                             100m (0%)     1 (4%)      0 (0%)           0 (0%)         74s\n  test-hotel-reservation-f819b557  reservation-78c9f7976b-5rfxh                                100m (0%)     1 (4%)      0 (0%)           0 (0%)         73s\n  test-hotel-reservation-f819b557  search-5c64c8f5bc-8gzg7                                     100m (0%)     1 (4%)      0 (0%)           0 (0%)         73s\n  test-hotel-reservation-f819b557  user-66d5d6f874-vtqcb                                       100m (0%)     1 (4%)      0 (0%)           0 (0%)         73s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                2200m (9%)   19100m (79%)\n  memory             1144Mi (3%)  50Mi (0%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\nEvents:              <none>\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.spec.nodeName}{\\\"\\n\\\"}{end}'\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 -o jsonpath='{range .items[*]}{.metadata.name}{\\\"\\t\\\"}{.spec.nodeName}{\\\"\\n\\\"}{end}'\")",
      "result": "consul-78c8d79bb-qtch4\tkind-worker\nfrontend-7fc7ddc9db-tp7km\tkind-worker\ngeo-84fbc958c7-v9jpp\tkind-worker\njaeger-67445b6dd6-mz9dd\tkind-worker\nmemcached-profile-668dcd6dbb-xk8vx\tkind-worker\nmemcached-rate-5b666ddfcb-s4s9p\tkind-worker\nmemcached-reserve-5bf87f5d54-gbdxj\tkind-worker\nmongodb-geo-5ff578bcb8-k5hd4\tkind-worker\nmongodb-profile-758cb77f9f-fb9r6\tkind-worker\nmongodb-rate-56cc8659c9-t765c\tkind-worker\nmongodb-recommendation-55699465f7-f7d95\tkind-worker\nmongodb-reservation-5994859869-4m59j\tkind-worker\nmongodb-user-969c6c449-2cdt2\tkind-worker\nprofile-8b6dd7c6c-57q4n\tkind-worker\nrate-7bdc978679-zkffp\tkind-worker\nrecommendation-6879fb56bf-hnbz5\tkind-worker\nreservation-78c9f7976b-5rfxh\tkind-worker\nsearch-5c64c8f5bc-8gzg7\tkind-worker\nuser-66d5d6f874-vtqcb\tkind-worker\nwrk2-job-f819b557-k4w7n\tkind-worker\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n kube-system\")",
      "command": "exec_shell(\"kubectl get pods -n kube-system\")",
      "result": "NAME                                         READY   STATUS    RESTARTS   AGE\ncoredns-668d6bf9bc-ht4q4                     1/1     Running   0          118m\ncoredns-668d6bf9bc-qclkn                     1/1     Running   0          118m\netcd-kind-control-plane                      1/1     Running   0          118m\nkindnet-4htl2                                1/1     Running   0          118m\nkindnet-9zgwj                                1/1     Running   0          118m\nkube-apiserver-kind-control-plane            1/1     Running   0          118m\nkube-controller-manager-kind-control-plane   1/1     Running   0          118m\nkube-proxy-ml7xq                             1/1     Running   0          118m\nkube-proxy-vwnmz                             1/1     Running   0          118m\nkube-scheduler-kind-control-plane            1/1     Running   0          118m\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl logs -n kube-system -l component=kube-scheduler --tail=50\")",
      "command": "exec_shell(\"kubectl logs -n kube-system -l component=kube-scheduler --tail=50\")",
      "result": "W1224 08:20:13.582290       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicasets\" in API group \"apps\" at the cluster scope\nE1224 08:20:13.582362       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"replicasets\\\" in API group \\\"apps\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:13.582296       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"statefulsets\" in API group \"apps\" at the cluster scope\nW1224 08:20:13.582396       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: namespaces is forbidden: User \"system:kube-scheduler\" cannot list resource \"namespaces\" in API group \"\" at the cluster scope\nE1224 08:20:13.582413       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"statefulsets\\\" in API group \\\"apps\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:13.582417       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: configmaps \"extension-apiserver-authentication\" is forbidden: User \"system:kube-scheduler\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\"\nE1224 08:20:13.582423       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"namespaces\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nE1224 08:20:13.582450       1 reflector.go:166] \"Unhandled Error\" err=\"runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps \\\"extension-apiserver-authentication\\\" is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"configmaps\\\" in API group \\\"\\\" in the namespace \\\"kube-system\\\"\" logger=\"UnhandledError\"\nW1224 08:20:13.582481       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: services is forbidden: User \"system:kube-scheduler\" cannot list resource \"services\" in API group \"\" at the cluster scope\nW1224 08:20:13.582497       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Pod: pods is forbidden: User \"system:kube-scheduler\" cannot list resource \"pods\" in API group \"\" at the cluster scope\nE1224 08:20:13.582501       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"services\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:13.582502       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User \"system:kube-scheduler\" cannot list resource \"poddisruptionbudgets\" in API group \"policy\" at the cluster scope\nW1224 08:20:13.582512       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csistoragecapacities\" in API group \"storage.k8s.io\" at the cluster scope\nE1224 08:20:13.582516       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"pods\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nE1224 08:20:13.582529       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"csistoragecapacities\\\" in API group \\\"storage.k8s.io\\\" at the cluster scope\" logger=\"UnhandledError\"\nE1224 08:20:13.582517       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"poddisruptionbudgets\\\" in API group \\\"policy\\\" at the cluster scope\" logger=\"UnhandledError\"\nE1224 08:20:13.582152       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"csinodes\\\" in API group \\\"storage.k8s.io\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:13.582543       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User \"system:kube-scheduler\" cannot list resource \"persistentvolumes\" in API group \"\" at the cluster scope\nE1224 08:20:13.582637       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"persistentvolumes\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:13.582661       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: nodes is forbidden: User \"system:kube-scheduler\" cannot list resource \"nodes\" in API group \"\" at the cluster scope\nW1224 08:20:13.582558       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"storageclasses\" in API group \"storage.k8s.io\" at the cluster scope\nE1224 08:20:13.582688       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"nodes\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nE1224 08:20:13.582699       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"storageclasses\\\" in API group \\\"storage.k8s.io\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.434549       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: namespaces is forbidden: User \"system:kube-scheduler\" cannot list resource \"namespaces\" in API group \"\" at the cluster scope\nE1224 08:20:14.434602       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"namespaces\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.480184       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: nodes is forbidden: User \"system:kube-scheduler\" cannot list resource \"nodes\" in API group \"\" at the cluster scope\nE1224 08:20:14.480248       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"nodes\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.582093       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"storageclasses\" in API group \"storage.k8s.io\" at the cluster scope\nE1224 08:20:14.582128       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"storageclasses\\\" in API group \\\"storage.k8s.io\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.603713       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: services is forbidden: User \"system:kube-scheduler\" cannot list resource \"services\" in API group \"\" at the cluster scope\nE1224 08:20:14.603762       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"services\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.620400       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.VolumeAttachment: volumeattachments.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"volumeattachments\" in API group \"storage.k8s.io\" at the cluster scope\nE1224 08:20:14.620481       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.VolumeAttachment: failed to list *v1.VolumeAttachment: volumeattachments.storage.k8s.io is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"volumeattachments\\\" in API group \\\"storage.k8s.io\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.686965       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csinodes\" in API group \"storage.k8s.io\" at the cluster scope\nE1224 08:20:14.687012       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"csinodes\\\" in API group \\\"storage.k8s.io\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.735170       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"statefulsets\" in API group \"apps\" at the cluster scope\nE1224 08:20:14.735213       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"statefulsets\\\" in API group \\\"apps\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.756570       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicationcontrollers\" in API group \"\" at the cluster scope\nE1224 08:20:14.756605       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"replicationcontrollers\\\" in API group \\\"\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.770934       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csistoragecapacities\" in API group \"storage.k8s.io\" at the cluster scope\nE1224 08:20:14.770999       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"csistoragecapacities\\\" in API group \\\"storage.k8s.io\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.857658       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User \"system:kube-scheduler\" cannot list resource \"poddisruptionbudgets\" in API group \"policy\" at the cluster scope\nE1224 08:20:14.857703       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"poddisruptionbudgets\\\" in API group \\\"policy\\\" at the cluster scope\" logger=\"UnhandledError\"\nW1224 08:20:14.893869       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: configmaps \"extension-apiserver-authentication\" is forbidden: User \"system:kube-scheduler\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\"\nE1224 08:20:14.893920       1 reflector.go:166] \"Unhandled Error\" err=\"runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps \\\"extension-apiserver-authentication\\\" is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"configmaps\\\" in API group \\\"\\\" in the namespace \\\"kube-system\\\"\" logger=\"UnhandledError\"\nW1224 08:20:14.948283       1 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicasets\" in API group \"apps\" at the cluster scope\nE1224 08:20:14.948321       1 reflector.go:166] \"Unhandled Error\" err=\"k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"replicasets\\\" in API group \\\"apps\\\" at the cluster scope\" logger=\"UnhandledError\"\nI1224 08:20:17.180776       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file\nI1224 08:20:17.783207       1 leaderelection.go:257] attempting to acquire leader lease kube-system/kube-scheduler...\nI1224 08:20:17.787628       1 leaderelection.go:271] successfully acquired lease kube-system/kube-scheduler\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get componentstatuses\")",
      "command": "exec_shell(\"kubectl get componentstatuses\")",
      "result": "NAME                 STATUS    MESSAGE   ERROR\ncontroller-manager   Healthy   ok        \nscheduler            Healthy   ok        \netcd-0               Healthy   ok        \nWarning: v1 ComponentStatus is deprecated in v1.19+\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl exec -n test-hotel-reservation -it $(kubectl get pod -n test-hotel-reservation -l io.kompose.service=frontend -o jsonpath='{.items[0].metadata.name}') -- nslookup mongodb-geo\")",
      "command": "exec_shell(\"kubectl exec -n test-hotel-reservation-f819b557 -it $(kubectl get pod -n test-hotel-reservation-f819b557 -l io.kompose.service=frontend -o jsonpath='{.items[0].metadata.name}') -- nslookup mongodb-geo\")",
      "result": "Unable to use a TTY - input is not a terminal or the right kind of file\nerror: Internal error occurred: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec \"f8b37cb58296186bbc412538df7428c31cc5c0e30f4a6bad2a29a0f9fc55a60d\": OCI runtime exec failed: exec failed: unable to start container process: exec: \"nslookup\": executable file not found in $PATH: unknown\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl exec -n test-hotel-reservation -it $(kubectl get pod -n test-hotel-reservation -l io.kompose.service=frontend -o jsonpath='{.items[0].metadata.name}') -- ping -c 3 mongodb-geo\")",
      "command": "exec_shell(\"kubectl exec -n test-hotel-reservation-f819b557 -it $(kubectl get pod -n test-hotel-reservation-f819b557 -l io.kompose.service=frontend -o jsonpath='{.items[0].metadata.name}') -- ping -c 3 mongodb-geo\")",
      "result": "Unable to use a TTY - input is not a terminal or the right kind of file\nerror: Internal error occurred: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec \"7b88f3e886667ea93e7160a3a8fd0f577b841fc11257253842addc1329cb46d6\": OCI runtime exec failed: exec failed: unable to start container process: exec: \"ping\": executable file not found in $PATH: unknown\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation --field-selector status.phase=Running\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 --field-selector status.phase=Running\")",
      "result": "NAME                                      READY   STATUS    RESTARTS      AGE\nconsul-78c8d79bb-qtch4                    1/1     Running   0             80s\nfrontend-7fc7ddc9db-tp7km                 1/1     Running   0             80s\ngeo-84fbc958c7-v9jpp                      0/1     Error     3 (39s ago)   59s\njaeger-67445b6dd6-mz9dd                   1/1     Running   0             80s\nmemcached-profile-668dcd6dbb-xk8vx        1/1     Running   0             80s\nmemcached-rate-5b666ddfcb-s4s9p           1/1     Running   0             80s\nmemcached-reserve-5bf87f5d54-gbdxj        1/1     Running   0             79s\nmongodb-geo-5ff578bcb8-k5hd4              1/1     Running   0             58s\nmongodb-profile-758cb77f9f-fb9r6          1/1     Running   0             80s\nmongodb-rate-56cc8659c9-t765c             1/1     Running   0             80s\nmongodb-recommendation-55699465f7-f7d95   1/1     Running   0             79s\nmongodb-reservation-5994859869-4m59j      1/1     Running   0             79s\nmongodb-user-969c6c449-2cdt2              1/1     Running   0             78s\nprofile-8b6dd7c6c-57q4n                   1/1     Running   1 (65s ago)   80s\nrate-7bdc978679-zkffp                     1/1     Running   1 (63s ago)   79s\nrecommendation-6879fb56bf-hnbz5           1/1     Running   1 (60s ago)   79s\nreservation-78c9f7976b-5rfxh              1/1     Running   0             78s\nsearch-5c64c8f5bc-8gzg7                   1/1     Running   0             78s\nuser-66d5d6f874-vtqcb                     1/1     Running   1 (62s ago)   78s\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get pods -n test-hotel-reservation --field-selector status.phase=Failed\")",
      "command": "exec_shell(\"kubectl get pods -n test-hotel-reservation-f819b557 --field-selector status.phase=Failed\")",
      "result": "No resources found in test-hotel-reservation-f819b557 namespace.\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl get all -n test-hotel-reservation -l io.kompose.service=geo -o yaml\")",
      "command": "exec_shell(\"kubectl get all -n test-hotel-reservation-f819b557 -l io.kompose.service=geo -o yaml\")",
      "result": "apiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Pod\n  metadata:\n    annotations:\n      kompose.cmd: kompose convert\n      kompose.version: 1.22.0 (955b78124)\n      sidecar.istio.io/statsInclusionPrefixes: cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\n      sidecar.istio.io/statsInclusionRegexps: http.*\n    creationTimestamp: \"2025-12-24T10:17:40Z\"\n    generateName: geo-84fbc958c7-\n    labels:\n      io.kompose.service: geo\n      pod-template-hash: 84fbc958c7\n    name: geo-84fbc958c7-v9jpp\n    namespace: test-hotel-reservation-f819b557\n    ownerReferences:\n    - apiVersion: apps/v1\n      blockOwnerDeletion: true\n      controller: true\n      kind: ReplicaSet\n      name: geo-84fbc958c7\n      uid: e0a2308d-768a-4cb4-b41b-d0da3fe5abeb\n    resourceVersion: \"74003\"\n    uid: 3a6acbd4-282e-4209-865e-b59fcdd95270\n  spec:\n    containers:\n    - command:\n      - geo\n      env:\n      - name: JAEGER_SAMPLE_RATIO\n        value: \"1\"\n      image: yinfangchen/hotelreservation:latest\n      imagePullPolicy: IfNotPresent\n      name: hotel-reserv-geo\n      ports:\n      - containerPort: 8083\n        protocol: TCP\n      resources:\n        limits:\n          cpu: \"1\"\n        requests:\n          cpu: 100m\n      terminationMessagePath: /dev/termination-log\n      terminationMessagePolicy: File\n      volumeMounts:\n      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n        name: kube-api-access-v5pbt\n        readOnly: true\n    dnsPolicy: ClusterFirst\n    enableServiceLinks: true\n    nodeName: kind-worker\n    preemptionPolicy: PreemptLowerPriority\n    priority: 0\n    restartPolicy: Always\n    schedulerName: default-scheduler\n    securityContext: {}\n    serviceAccount: default\n    serviceAccountName: default\n    terminationGracePeriodSeconds: 30\n    tolerations:\n    - effect: NoExecute\n      key: node.kubernetes.io/not-ready\n      operator: Exists\n      tolerationSeconds: 300\n    - effect: NoExecute\n      key: node.kubernetes.io/unreachable\n      operator: Exists\n      tolerationSeconds: 300\n    volumes:\n    - name: kube-api-access-v5pbt\n      projected:\n        defaultMode: 420\n        sources:\n        - serviceAccountToken:\n            expirationSeconds: 3607\n            path: token\n        - configMap:\n            items:\n            - key: ca.crt\n              path: ca.crt\n            name: kube-root-ca.crt\n        - downwardAPI:\n            items:\n            - fieldRef:\n                apiVersion: v1\n                fieldPath: metadata.namespace\n              path: namespace\n  status:\n    conditions:\n    - lastProbeTime: null\n      lastTransitionTime: \"2025-12-24T10:17:42Z\"\n      status: \"True\"\n      type: PodReadyToStartContainers\n    - lastProbeTime: null\n      lastTransitionTime: \"2025-12-24T10:17:40Z\"\n      status: \"True\"\n      type: Initialized\n    - lastProbeTime: null\n      lastTransitionTime: \"2025-12-24T10:17:48Z\"\n      message: 'containers with unready status: [hotel-reserv-geo]'\n      reason: ContainersNotReady\n      status: \"False\"\n      type: Ready\n    - lastProbeTime: null\n      lastTransitionTime: \"2025-12-24T10:17:48Z\"\n      message: 'containers with unready status: [hotel-reserv-geo]'\n      reason: ContainersNotReady\n      status: \"False\"\n      type: ContainersReady\n    - lastProbeTime: null\n      lastTransitionTime: \"2025-12-24T10:17:40Z\"\n      status: \"True\"\n      type: PodScheduled\n    containerStatuses:\n    - containerID: containerd://102e688d506d6e9e95d06ce624aed0e98d3e57b899ecf5e9cbbc79b662ec357d\n      image: docker.io/yinfangchen/hotelreservation:latest\n      imageID: docker.io/library/import-2025-12-24@sha256:94b33314764103ff9b6f3109366b5b58873f50f9bb3152bf29e3062f95521b13\n      lastState:\n        terminated:\n          containerID: containerd://102e688d506d6e9e95d06ce624aed0e98d3e57b899ecf5e9cbbc79b662ec357d\n          exitCode: 2\n          finishedAt: \"2025-12-24T10:18:27Z\"\n          reason: Error\n          startedAt: \"2025-12-24T10:18:27Z\"\n      name: hotel-reserv-geo\n      ready: false\n      restartCount: 3\n      started: false\n      state:\n        waiting:\n          message: back-off 40s restarting failed container=hotel-reserv-geo pod=geo-84fbc958c7-v9jpp_test-hotel-reservation-f819b557(3a6acbd4-282e-4209-865e-b59fcdd95270)\n          reason: CrashLoopBackOff\n      volumeMounts:\n      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n        name: kube-api-access-v5pbt\n        readOnly: true\n        recursiveReadOnly: Disabled\n    hostIP: 172.18.0.2\n    hostIPs:\n    - ip: 172.18.0.2\n    phase: Running\n    podIP: 10.244.1.208\n    podIPs:\n    - ip: 10.244.1.208\n    qosClass: Burstable\n    startTime: \"2025-12-24T10:17:40Z\"\n- apiVersion: v1\n  kind: Service\n  metadata:\n    annotations:\n      kompose.cmd: kompose convert\n      kompose.version: 1.22.0 (955b78124)\n      kubectl.kubernetes.io/last-applied-configuration: |\n        {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{\"kompose.cmd\":\"kompose convert\",\"kompose.version\":\"1.22.0 (955b78124)\"},\"creationTimestamp\":null,\"labels\":{\"io.kompose.service\":\"geo\"},\"name\":\"geo\",\"namespace\":\"test-hotel-reservation-f819b557\"},\"spec\":{\"ports\":[{\"name\":\"8083\",\"port\":8083,\"targetPort\":8083}],\"selector\":{\"io.kompose.service\":\"geo\"}},\"status\":{\"loadBalancer\":{}}}\n    creationTimestamp: \"2025-12-24T10:17:19Z\"\n    labels:\n      io.kompose.service: geo\n    name: geo\n    namespace: test-hotel-reservation-f819b557\n    resourceVersion: \"73055\"\n    uid: 256a7464-08f2-4cd2-a082-e33143d3c9e6\n  spec:\n    clusterIP: 10.96.129.251\n    clusterIPs:\n    - 10.96.129.251\n    internalTrafficPolicy: Cluster\n    ipFamilies:\n    - IPv4\n    ipFamilyPolicy: SingleStack\n    ports:\n    - name: \"8083\"\n      port: 8083\n      protocol: TCP\n      targetPort: 8083\n    selector:\n      io.kompose.service: geo\n    sessionAffinity: None\n    type: ClusterIP\n  status:\n    loadBalancer: {}\n- apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    annotations:\n      deployment.kubernetes.io/revision: \"1\"\n      kompose.cmd: kompose convert\n      kompose.version: 1.22.0 (955b78124)\n      kubectl.kubernetes.io/last-applied-configuration: |\n        {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"annotations\":{\"kompose.cmd\":\"kompose convert\",\"kompose.version\":\"1.22.0 (955b78124)\"},\"creationTimestamp\":null,\"labels\":{\"io.kompose.service\":\"geo\"},\"name\":\"geo\",\"namespace\":\"test-hotel-reservation-f819b557\"},\"spec\":{\"replicas\":1,\"selector\":{\"matchLabels\":{\"io.kompose.service\":\"geo\"}},\"strategy\":{},\"template\":{\"metadata\":{\"annotations\":{\"kompose.cmd\":\"kompose convert\",\"kompose.version\":\"1.22.0 (955b78124)\",\"sidecar.istio.io/statsInclusionPrefixes\":\"cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\",\"sidecar.istio.io/statsInclusionRegexps\":\"http.*\"},\"creationTimestamp\":null,\"labels\":{\"io.kompose.service\":\"geo\"}},\"spec\":{\"containers\":[{\"command\":[\"geo\"],\"env\":[{\"name\":\"JAEGER_SAMPLE_RATIO\",\"value\":\"1\"}],\"image\":\"yinfangchen/hotelreservation:latest\",\"imagePullPolicy\":\"IfNotPresent\",\"name\":\"hotel-reserv-geo\",\"ports\":[{\"containerPort\":8083}],\"resources\":{\"limits\":{\"cpu\":\"1000m\"},\"requests\":{\"cpu\":\"100m\"}}}],\"restartPolicy\":\"Always\"}}},\"status\":{}}\n    creationTimestamp: \"2025-12-24T10:17:19Z\"\n    generation: 1\n    labels:\n      io.kompose.service: geo\n    name: geo\n    namespace: test-hotel-reservation-f819b557\n    resourceVersion: \"73814\"\n    uid: 3071f6da-cc98-448f-8592-ce58e209d619\n  spec:\n    progressDeadlineSeconds: 600\n    replicas: 1\n    revisionHistoryLimit: 10\n    selector:\n      matchLabels:\n        io.kompose.service: geo\n    strategy:\n      rollingUpdate:\n        maxSurge: 25%\n        maxUnavailable: 25%\n      type: RollingUpdate\n    template:\n      metadata:\n        annotations:\n          kompose.cmd: kompose convert\n          kompose.version: 1.22.0 (955b78124)\n          sidecar.istio.io/statsInclusionPrefixes: cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\n          sidecar.istio.io/statsInclusionRegexps: http.*\n        creationTimestamp: null\n        labels:\n          io.kompose.service: geo\n      spec:\n        containers:\n        - command:\n          - geo\n          env:\n          - name: JAEGER_SAMPLE_RATIO\n            value: \"1\"\n          image: yinfangchen/hotelreservation:latest\n          imagePullPolicy: IfNotPresent\n          name: hotel-reserv-geo\n          ports:\n          - containerPort: 8083\n            protocol: TCP\n          resources:\n            limits:\n              cpu: \"1\"\n            requests:\n              cpu: 100m\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        schedulerName: default-scheduler\n        securityContext: {}\n        terminationGracePeriodSeconds: 30\n  status:\n    conditions:\n    - lastTransitionTime: \"2025-12-24T10:17:19Z\"\n      lastUpdateTime: \"2025-12-24T10:17:24Z\"\n      message: ReplicaSet \"geo-84fbc958c7\" has successfully progressed.\n      reason: NewReplicaSetAvailable\n      status: \"True\"\n      type: Progressing\n    - lastTransitionTime: \"2025-12-24T10:17:48Z\"\n      lastUpdateTime: \"2025-12-24T10:17:48Z\"\n      message: Deployment does not have minimum availability.\n      reason: MinimumReplicasUnavailable\n      status: \"False\"\n      type: Available\n    observedGeneration: 1\n    replicas: 1\n    unavailableReplicas: 1\n    updatedReplicas: 1\n- apiVersion: apps/v1\n  kind: ReplicaSet\n  metadata:\n    annotations:\n      deployment.kubernetes.io/desired-replicas: \"1\"\n      deployment.kubernetes.io/max-replicas: \"2\"\n      deployment.kubernetes.io/revision: \"1\"\n      kompose.cmd: kompose convert\n      kompose.version: 1.22.0 (955b78124)\n    creationTimestamp: \"2025-12-24T10:17:19Z\"\n    generation: 1\n    labels:\n      io.kompose.service: geo\n      pod-template-hash: 84fbc958c7\n    name: geo-84fbc958c7\n    namespace: test-hotel-reservation-f819b557\n    ownerReferences:\n    - apiVersion: apps/v1\n      blockOwnerDeletion: true\n      controller: true\n      kind: Deployment\n      name: geo\n      uid: 3071f6da-cc98-448f-8592-ce58e209d619\n    resourceVersion: \"73813\"\n    uid: e0a2308d-768a-4cb4-b41b-d0da3fe5abeb\n  spec:\n    replicas: 1\n    selector:\n      matchLabels:\n        io.kompose.service: geo\n        pod-template-hash: 84fbc958c7\n    template:\n      metadata:\n        annotations:\n          kompose.cmd: kompose convert\n          kompose.version: 1.22.0 (955b78124)\n          sidecar.istio.io/statsInclusionPrefixes: cluster.outbound,cluster_manager,listener_manager,http_mixer_filter,tcp_mixer_filter,server,cluster.xds-grp,listener,connection_manager\n          sidecar.istio.io/statsInclusionRegexps: http.*\n        creationTimestamp: null\n        labels:\n          io.kompose.service: geo\n          pod-template-hash: 84fbc958c7\n      spec:\n        containers:\n        - command:\n          - geo\n          env:\n          - name: JAEGER_SAMPLE_RATIO\n            value: \"1\"\n          image: yinfangchen/hotelreservation:latest\n          imagePullPolicy: IfNotPresent\n          name: hotel-reserv-geo\n          ports:\n          - containerPort: 8083\n            protocol: TCP\n          resources:\n            limits:\n              cpu: \"1\"\n            requests:\n              cpu: 100m\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        schedulerName: default-scheduler\n        securityContext: {}\n        terminationGracePeriodSeconds: 30\n  status:\n    fullyLabeledReplicas: 1\n    observedGeneration: 1\n    replicas: 1\nkind: List\nmetadata:\n  resourceVersion: \"\"\n",
      "success": true,
      "attempt": 1
    },
    {
      "original_command": "exec_shell(\"kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n test-hotel-reservation\")",
      "command": "exec_shell(\"kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n test-hotel-reservation-f819b557\")",
      "result": "Error: Failed to execute command: kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n test-hotel-reservation-f819b557\nError: Command 'kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n test-hotel-reservation-f819b557' timed out after 10 seconds",
      "success": false,
      "attempt": 1
    }
  ]
}