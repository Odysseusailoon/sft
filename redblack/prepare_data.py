#!/usr/bin/env python3
"""
RedBlackBench SFT Data Preparation Script

å°† HuggingFace æ•°æ®ä¸Ž scenarios ç›®å½•ä¸­çš„ prompt æ¨¡æ¿æ­£ç¡®æ˜ å°„ã€‚

å…³é”®è®¾è®¡:
1. ä»Ž scenarios/*.py åŠ è½½å®˜æ–¹ system prompt æ¨¡æ¿
2. éªŒè¯ HF æ•°æ®ä¸­çš„ input æ˜¯å¦åŒ…å«æ­£ç¡®çš„ scenario prompt
3. ä½¿ç”¨åœºæ™¯ç‰¹å®šçš„ system prompt è€Œéžé€šç”¨ prompt
4. æ”¯æŒæŒ‰åœºæ™¯åˆ†å‰²æ•°æ®ä»¥è¿›è¡Œé’ˆå¯¹æ€§è¯„ä¼°
"""

import json
import os
import random
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
from dataclasses import dataclass


def _load_scenario_prompts() -> Dict[str, str]:
    """
    ä»Žåœºæ™¯æ–‡ä»¶ä¸­æå– system prompts
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æžï¼Œé¿å…å¯¼å…¥æ•´ä¸ªæ¨¡å—ï¼ˆPythonç‰ˆæœ¬å…¼å®¹æ€§ï¼‰
    """
    scenarios_dir = Path(__file__).parent.parent / "redblackbench" / "scenarios"
    
    prompt_names = {
        "agi_safety.py": ("AGI_SAFETY_SYSTEM_PROMPT", "agi_safety"),
        "pandemic.py": ("PANDEMIC_SYSTEM_PROMPT", "pandemic_vaccines"),
        "climate.py": ("CLIMATE_SYSTEM_PROMPT", "climate_cooperation"),
        "election_crisis.py": ("ELECTION_SYSTEM_PROMPT", "election_crisis"),
        "standards_coordination.py": ("STANDARDS_SYSTEM_PROMPT", "standards_coordination"),
    }
    
    prompts = {}
    
    for filename, (var_name, scenario_id) in prompt_names.items():
        filepath = scenarios_dir / filename
        if filepath.exists():
            content = filepath.read_text()
            # ä½¿ç”¨æ­£åˆ™æå–å¤šè¡Œå­—ç¬¦ä¸²
            pattern = rf'{var_name}\s*=\s*"""(.*?)"""'
            match = re.search(pattern, content, re.DOTALL)
            if match:
                prompts[scenario_id] = match.group(1)
    
    return prompts


# åŠ è½½åœºæ™¯ prompts
SCENARIO_PROMPTS = _load_scenario_prompts()

# åœºæ™¯æè¿° (ç”¨äºŽæ—¥å¿—)
SCENARIO_DESCRIPTIONS = {
    "agi_safety": "AGI Safety Research Sharing",
    "pandemic_vaccines": "Pandemic Vaccine Allocation", 
    "climate_cooperation": "Climate Adaptation Strategy",
    "election_crisis": "Election Year Economic Crisis (HARD)",
    "standards_coordination": "Software Standards Coordination (NEUTRAL)",
}


@dataclass
class DataStats:
    """æ•°æ®ç»Ÿè®¡"""
    total: int = 0
    by_scenario: Dict[str, int] = None
    by_round: Dict[int, int] = None
    vote_a: int = 0
    vote_b: int = 0
    avg_input_len: float = 0
    avg_output_len: float = 0
    prompt_match_rate: float = 0
    
    def __post_init__(self):
        if self.by_scenario is None:
            self.by_scenario = defaultdict(int)
        if self.by_round is None:
            self.by_round = defaultdict(int)


def load_hf_datasets(data_dir: str) -> List[Dict]:
    """åŠ è½½ HuggingFace æ•°æ®é›†"""
    all_examples = []
    data_path = Path(data_dir)
    
    for fname in sorted(data_path.glob("*.json")):
        print(f"Loading {fname.name}...")
        with open(fname, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        examples = data.get('examples', [])
        print(f"  â†’ {len(examples)} examples")
        all_examples.extend(examples)
    
    print(f"\nâœ“ Total loaded: {len(all_examples)} examples")
    return all_examples


def extract_scenario_system_prompt(scenario_id: str, agent_name: str, team_name: str = "Team A") -> str:
    """
    æ ¹æ® scenario_id æå–å¹¶æ ¼å¼åŒ– system prompt
    
    HF æ•°æ®ä¸­çš„ input å·²ç»åŒ…å«äº†æ ¼å¼åŒ–åŽçš„ system promptï¼Œ
    è¿™é‡Œæˆ‘ä»¬ç”ŸæˆæœŸæœ›çš„ system prompt ç”¨äºŽéªŒè¯ã€‚
    """
    template = SCENARIO_PROMPTS.get(scenario_id)
    if not template:
        return None
    
    # æ ¼å¼åŒ– prompt (ä¸Ž scenarios ä¸­çš„æ ¼å¼ä¸€è‡´)
    return template.format(
        agent_id=agent_name,
        team_name=team_name,
    )


def validate_prompt_mapping(example: Dict) -> Tuple[bool, str]:
    """
    éªŒè¯ HF æ•°æ®ä¸­çš„ input æ˜¯å¦åŒ…å«æ­£ç¡®çš„ scenario prompt
    
    è¿”å›ž: (æ˜¯å¦åŒ¹é…, é”™è¯¯ä¿¡æ¯)
    """
    scenario_id = example.get('metadata', {}).get('scenario_id', '')
    input_text = example.get('input', '')
    agent_name = example.get('agent_name', '')
    
    if scenario_id not in SCENARIO_PROMPTS:
        return False, f"Unknown scenario: {scenario_id}"
    
    # æ£€æŸ¥ input ä¸­æ˜¯å¦åŒ…å«å…³é”®åœºæ™¯æ ‡è¯†
    scenario_markers = {
        "agi_safety": ["AI Safety Research Strategy Committee", "alignment risk"],
        "pandemic_vaccines": ["National Pandemic Response Committee", "vaccine"],
        "climate_cooperation": ["National Climate Adaptation Committee", "sea levels"],
        "election_crisis": ["Emergency Economic Coordination Task Force", "election"],
        "standards_coordination": ["Technical Standards Committee", "open-source library"],
    }
    
    markers = scenario_markers.get(scenario_id, [])
    for marker in markers:
        if marker.lower() in input_text.lower():
            return True, ""
    
    return False, f"Missing scenario markers for {scenario_id}"


def convert_to_chat_format(
    example: Dict, 
    use_scenario_system_prompt: bool = True
) -> Optional[Dict]:
    """
    å°†å•ä¸ªæ ·æœ¬è½¬æ¢ä¸º chat æ ¼å¼
    
    è®¾è®¡å†³ç­–:
    1. å¦‚æžœ use_scenario_system_prompt=Trueï¼Œä½¿ç”¨åœºæ™¯ç‰¹å®šçš„ system prompt
    2. input å­—æ®µå·²ç»åŒ…å«å®Œæ•´çš„åœºæ™¯è¯´æ˜Žï¼Œä½œä¸º user message
    3. output ä½œä¸º assistant response
    """
    scenario_id = example.get('metadata', {}).get('scenario_id', '')
    agent_name = example.get('agent_name', 'Advisor')
    input_text = example.get('input', '')
    output_text = example.get('output', '')
    
    if not input_text or not output_text:
        return None
    
    # æž„å»ºæ¶ˆæ¯
    messages = []
    
    if use_scenario_system_prompt:
        # ä½¿ç”¨åœºæ™¯ç‰¹å®šçš„ç®€åŒ– system prompt
        # æ³¨æ„: input ä¸­å·²ç»åŒ…å«å®Œæ•´çš„åœºæ™¯è¯´æ˜Ž
        system_prompt = f"""You are {agent_name}, a strategic advisor in a multi-round cooperation game.

Your task:
1. Analyze the current situation and game history
2. Consider your teammates' perspectives  
3. Provide reasoned analysis
4. Cast your vote: VOTE: A or VOTE: B

Remember: Option A represents cooperation for collective benefit. Option B prioritizes your group's immediate advantage."""
        
        messages.append({"role": "system", "content": system_prompt})
    
    messages.append({"role": "user", "content": input_text})
    messages.append({"role": "assistant", "content": output_text})
    
    return {
        "messages": messages,
        "metadata": {
            "trajectory_id": example.get('trajectory_id', ''),
            "round_index": example.get('round_index', 0),
            "turn": example.get('turn', 0),
            "agent_name": agent_name,
            "scenario_id": scenario_id,
        }
    }


def analyze_data(examples: List[Dict]) -> DataStats:
    """åˆ†æžæ•°æ®åˆ†å¸ƒå’Œè´¨é‡"""
    stats = DataStats()
    stats.total = len(examples)
    
    input_lengths = []
    output_lengths = []
    prompt_matches = 0
    
    vote_pattern = re.compile(r'VOTE:\s*([AB])', re.IGNORECASE)
    
    for ex in examples:
        scenario = ex.get('metadata', {}).get('scenario_id', 'unknown')
        stats.by_scenario[scenario] += 1
        stats.by_round[ex.get('round_index', 0)] += 1
        
        output = ex.get('output', '')
        input_text = ex.get('input', '')
        
        # ç»Ÿè®¡æŠ•ç¥¨
        match = vote_pattern.search(output)
        if match:
            if match.group(1).upper() == 'A':
                stats.vote_a += 1
            else:
                stats.vote_b += 1
        
        input_lengths.append(len(input_text))
        output_lengths.append(len(output))
        
        # éªŒè¯ prompt æ˜ å°„
        is_valid, _ = validate_prompt_mapping(ex)
        if is_valid:
            prompt_matches += 1
    
    stats.avg_input_len = sum(input_lengths) / len(input_lengths) if input_lengths else 0
    stats.avg_output_len = sum(output_lengths) / len(output_lengths) if output_lengths else 0
    stats.prompt_match_rate = prompt_matches / stats.total if stats.total > 0 else 0
    
    return stats


def split_by_trajectory(
    examples: List[Dict],
    train_ratio: float = 0.85,
    val_ratio: float = 0.10,
    seed: int = 42
) -> Tuple[List[Dict], List[Dict], List[Dict]]:
    """
    æŒ‰ trajectory åˆ†å‰²æ•°æ®ï¼Œç¡®ä¿:
    1. åŒä¸€ trajectory çš„æ‰€æœ‰æ ·æœ¬åœ¨åŒä¸€ split
    2. å„åœºæ™¯åœ¨å„ split ä¸­å‡åŒ€åˆ†å¸ƒ
    """
    random.seed(seed)
    
    # æŒ‰åœºæ™¯å’Œ trajectory åˆ†ç»„
    scenario_trajectories = defaultdict(lambda: defaultdict(list))
    for ex in examples:
        scenario = ex.get('metadata', {}).get('scenario_id', 'unknown')
        tid = ex.get('trajectory_id', '') or ex.get('metadata', {}).get('trajectory_id', 'unknown')
        scenario_trajectories[scenario][tid].append(ex)
    
    train, val, test = [], [], []
    
    print("\nðŸ“Š Splitting by scenario:")
    for scenario in sorted(scenario_trajectories.keys()):
        trajectories = scenario_trajectories[scenario]
        tids = list(trajectories.keys())
        random.shuffle(tids)
        
        n = len(tids)
        train_end = int(n * train_ratio)
        val_end = int(n * (train_ratio + val_ratio))
        
        train_tids = set(tids[:train_end])
        val_tids = set(tids[train_end:val_end])
        test_tids = set(tids[val_end:])
        
        scenario_train = []
        scenario_val = []
        scenario_test = []
        
        for tid, exs in trajectories.items():
            if tid in train_tids:
                scenario_train.extend(exs)
            elif tid in val_tids:
                scenario_val.extend(exs)
            else:
                scenario_test.extend(exs)
        
        desc = SCENARIO_DESCRIPTIONS.get(scenario, scenario)
        print(f"  {desc}: train={len(scenario_train)}, val={len(scenario_val)}, test={len(scenario_test)}")
        
        train.extend(scenario_train)
        val.extend(scenario_val)
        test.extend(scenario_test)
    
    return train, val, test


def save_jsonl(data: List[Dict], filepath: str):
    """ä¿å­˜ä¸º JSONL æ ¼å¼"""
    with open(filepath, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    print(f"  âœ“ Saved {len(data):,} samples â†’ {filepath}")


def save_by_scenario(examples: List[Dict], output_dir: str, split_name: str):
    """æŒ‰åœºæ™¯åˆ†åˆ«ä¿å­˜"""
    scenario_data = defaultdict(list)
    for ex in examples:
        scenario = ex.get('metadata', {}).get('scenario_id', 'unknown')
        scenario_data[scenario].append(ex)
    
    for scenario, data in sorted(scenario_data.items()):
        filepath = os.path.join(output_dir, f"{split_name}_{scenario}.jsonl")
        save_jsonl(data, filepath)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Prepare RedBlackBench SFT data with proper prompt mapping")
    parser.add_argument("--data_dir", default="hf_dataset", help="HuggingFace data directory")
    parser.add_argument("--output_dir", default="data", help="Output directory")
    parser.add_argument("--train_ratio", type=float, default=0.85)
    parser.add_argument("--val_ratio", type=float, default=0.10)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--save_by_scenario", action="store_true", help="Save separate files by scenario")
    parser.add_argument("--validate_only", action="store_true", help="Only validate, don't save")
    args = parser.parse_args()
    
    print("=" * 70)
    print("ðŸŽ® RedBlackBench SFT Data Preparation")
    print("=" * 70)
    
    # æ˜¾ç¤ºåœºæ™¯ prompt æ˜ å°„
    print("\nðŸ“‹ Scenario Prompt Mapping:")
    for scenario_id, desc in SCENARIO_DESCRIPTIONS.items():
        prompt_preview = SCENARIO_PROMPTS[scenario_id][:100].replace('\n', ' ')
        print(f"  â€¢ {scenario_id}: {desc}")
        print(f"    Preview: \"{prompt_preview}...\"")
    
    # åŠ è½½æ•°æ®
    print("\n" + "=" * 70)
    print("ðŸ“¥ Loading HuggingFace Data")
    print("=" * 70)
    raw_examples = load_hf_datasets(args.data_dir)
    
    if not raw_examples:
        print("âŒ No data found!")
        return
    
    # åˆ†æžåŽŸå§‹æ•°æ®
    print("\n" + "=" * 70)
    print("ðŸ“Š Raw Data Analysis")
    print("=" * 70)
    stats = analyze_data(raw_examples)
    
    print(f"\nTotal samples: {stats.total:,}")
    print(f"\nBy Scenario:")
    for scenario, count in sorted(stats.by_scenario.items()):
        desc = SCENARIO_DESCRIPTIONS.get(scenario, scenario)
        print(f"  {desc}: {count:,} ({100*count/stats.total:.1f}%)")
    
    print(f"\nVote Distribution:")
    print(f"  VOTE A (cooperation): {stats.vote_a:,} ({100*stats.vote_a/stats.total:.1f}%)")
    print(f"  VOTE B (defection):   {stats.vote_b:,} ({100*stats.vote_b/stats.total:.1f}%)")
    
    print(f"\nLength Statistics:")
    print(f"  Input:  avg {stats.avg_input_len:,.0f} chars")
    print(f"  Output: avg {stats.avg_output_len:,.0f} chars")
    
    print(f"\nPrompt Mapping Validation:")
    print(f"  Match rate: {100*stats.prompt_match_rate:.1f}%")
    
    if args.validate_only:
        print("\nâœ“ Validation complete (--validate_only)")
        return
    
    # è½¬æ¢ä¸º chat æ ¼å¼
    print("\n" + "=" * 70)
    print("ðŸ”„ Converting to Chat Format")
    print("=" * 70)
    
    chat_examples = []
    failed = 0
    for ex in raw_examples:
        converted = convert_to_chat_format(ex, use_scenario_system_prompt=True)
        if converted:
            chat_examples.append(converted)
        else:
            failed += 1
    
    print(f"  Converted: {len(chat_examples):,}")
    if failed > 0:
        print(f"  Failed: {failed}")
    
    # åˆ†å‰²æ•°æ®
    print("\n" + "=" * 70)
    print("âœ‚ï¸ Splitting Data")
    print("=" * 70)
    
    train, val, test = split_by_trajectory(
        chat_examples,
        args.train_ratio,
        args.val_ratio,
        args.seed
    )
    
    print(f"\nFinal Split:")
    print(f"  Train: {len(train):,} ({100*len(train)/len(chat_examples):.1f}%)")
    print(f"  Val:   {len(val):,} ({100*len(val)/len(chat_examples):.1f}%)")
    print(f"  Test:  {len(test):,} ({100*len(test)/len(chat_examples):.1f}%)")
    
    # ä¿å­˜æ•°æ®
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("\n" + "=" * 70)
    print("ðŸ’¾ Saving Data")
    print("=" * 70)
    
    save_jsonl(train, os.path.join(args.output_dir, "train.jsonl"))
    save_jsonl(val, os.path.join(args.output_dir, "val.jsonl"))
    save_jsonl(test, os.path.join(args.output_dir, "test.jsonl"))
    
    if args.save_by_scenario:
        print("\n  Saving by scenario...")
        save_by_scenario(train, args.output_dir, "train")
        save_by_scenario(val, args.output_dir, "val")
        save_by_scenario(test, args.output_dir, "test")
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_dict = {
        "total_examples": len(chat_examples),
        "train_size": len(train),
        "val_size": len(val),
        "test_size": len(test),
        "scenarios": dict(stats.by_scenario),
        "vote_distribution": {"A": stats.vote_a, "B": stats.vote_b},
        "prompt_match_rate": stats.prompt_match_rate,
        "scenario_descriptions": SCENARIO_DESCRIPTIONS,
    }
    stats_path = os.path.join(args.output_dir, "stats.json")
    with open(stats_path, 'w') as f:
        json.dump(stats_dict, f, indent=2, ensure_ascii=False)
    print(f"\n  âœ“ Stats â†’ {stats_path}")
    
    # æ˜¾ç¤ºæ ·æœ¬
    print("\n" + "=" * 70)
    print("ðŸ“ Sample Output")
    print("=" * 70)
    if train:
        sample = train[0]
        print(f"\nScenario: {sample['metadata']['scenario_id']}")
        print(f"Agent: {sample['metadata']['agent_name']}")
        print(f"Round: {sample['metadata']['round_index']}")
        print(f"\nMessages ({len(sample['messages'])}):")
        for i, msg in enumerate(sample['messages']):
            role = msg['role'].upper()
            content = msg['content']
            if len(content) > 300:
                content = content[:300] + "..."
            print(f"\n  [{role}]")
            print(f"  {content}")
    
    print("\n" + "=" * 70)
    print("âœ… Data preparation complete!")
    print("=" * 70)


if __name__ == "__main__":
    main()

